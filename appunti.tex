\documentclass[hidelinks, 10pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{bbm}
\usepackage{marvosym}
\usepackage{xcolor}
\usepackage{blindtext}
\usepackage{listings}
\usepackage{float}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{cancel}
\usepackage{breqn}
\usepackage{verbatim}
\usepackage{mathtools}
\usepackage{epsfig}
\usepackage{epstopdf}
\usepackage{titling}
\usepackage{url}
\usepackage{array}
\usepackage{tikz}
% \usepackage[a4paper]{geometry}

\usetikzlibrary{arrows, automata, backgrounds, calendar, chains, matrix, mindmap, patterns, petri, shadows, shapes.geometric, shapes.misc, spy, trees}

\author{Andreas Veeser}
\date{A.A. 2017-2018}
\title{Calcolo numerico 2}

\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\Mat}{Mat}

\begin{document}
\providecommand{\defeq}{\vcentcolon=}
\providecommand{\eqdef}{=\vcentcolon}
\providecommand{\compl}[1]{\prescript{c}{}{#1}}
\providecommand{\norm}[1]{\Vert {#1} \Vert\,}
\providecommand{\card}[1]{\vert {#1} \vert\,}
\providecommand{\ristrettaA}[1]{_{\vert_{#1}}}

\theoremstyle{plain}
\newtheorem{thm}{Teorema}[]
\renewcommand{\thesection}{\arabic{section}}

\theoremstyle{definition}
\newtheorem{defn}[]{Definizione}
\newtheorem{prop}[]{Proposizione}
\newtheorem{cor}[]{Corollario}
\newtheorem{lem}[]{Lemma}
\newtheorem{oss}[]{Osservazione}
\newtheorem{nota}[]{Nota}
\newtheorem{es}[]{Esempio}
\newtheorem{ex}[]{Esercizio}

\maketitle
\chapter{Introduzione}
\section{Discretizzazione di un problema ai valori iniziali}
\subsection{Problema ai valori iniziali}
Dati:
\begin{itemize}
\item $ t_{0} \in \mathbb{R} $ tempo iniziale;
\item $ T \in \mathbb{R} $ con $ T > t_{0} $ tempo finale;
\item $ I = [t_{0}, T] $ un intervallo;
\item $ f: I \times \mathbb{R} \to \mathbb{R} $ una funzione;
\item $ v \in \mathbb{R} $ valore iniziale;
\end{itemize}

l'obiettivo di un problema ai valori iniziali \`e quello di trovare $ u: I \to \mathbb{R} $ tale che
\[
\begin{cases}
u' = f(\cdot, u) \\
u(t_{0}) = v
\end{cases}
\]

o, meglio, $ \forall\ t \in I $

\begin{equation}	\label{eq:PVI}
\begin{cases}
u'(t) = f \left( t, u(t) \right) \\
u(t_{0}) = v
\end{cases}
\end{equation}

In generale $ u $ non \`e nota esplicitamente e quindi l'ottenere informazioni quantitative, come ad esempio $ u(T) $, richiede una risoluzione numerica. In $ (\ref{eq:PVI}) $ si celano un'infinit\`a di condizioni.

\subsection{Le griglie}
Un'equazione differenziale ordinaria (EDO) consiste di un numero infinito di condizioni, dato che $ t \in I $, linearmente indipendenti. Non si possono neanche verificare sul computer in tempo finito. Pertanto, si introduce una griglia (o \emph{mesh}) dell'intervallo $ I $:

\[ M_{N} = \{ t_{n} \defeq t_{0} + n \tau : n = 0, \dotsc, N \} \]

dove:
\begin{itemize}
\item $ N \in \mathbb{N} $ \`e il numero di passi;
\item $ \tau \defeq \frac{T - t_{0}}{N} $ \`e il passo temporale.
\end{itemize}

% TODO: disegno

\subsection{Sostituzione dell'operatore differenziale}
Data ad esempio $ t \in U_{N} $, neanche $ f \left( t, u(t) \right) = u'(t) $ \`e verificabile al computer poich\'e in generale

\[ u'(t) = \lim\limits_{h \to 0} \frac{u(t + h) - u(t)}{h} \]

coinvolge un numero infinito di operazioni. Se si usa l'approssimazione

\[ u'(t) \approx \frac{u(t + h) - u(t)}{h} \]

con $ t = t_{n} $ e $ h = t_{n + 1} - t_{n} = \tau $ si ottiene

\[
\begin{cases}
u(t_{0}) = v \\
\frac{u(t_{n + 1}) - u(t_{n})}{\tau} \approx f \left( t_{n}, u(t_{n}) \right)
\end{cases}
\]

Il pregio \`e che questo sistema \`e discreto, rispetto a $ (\ref{eq:PVI}) $.

Sostituendo $ \{ u(t_{n}) \}_{n = 0}^{N} $ con una successione finita incognita $ \{ U_{n} \} $ si ottiene

\begin{equation}	\label{eq:EE}
\begin{cases}
U_{0} = v \\
\frac{U_{n + 1} - U_{n}}{\tau} = f(t_{n}, U_{n})
\end{cases}
\end{equation}

Dal momento che $ \frac{U_{n + 1} - U_{n}}{\tau} = f(t_{n}, U_{n}) \iff U_{n + 1} = U_{n} + \tau f(t_{n}, U_{n}) $, gli $ U_{n} $ possono essere facilmente (persino velocemente) calcolati con un'interazione da $ U_{0} = v $. $ (\ref{eq:EE}) $ viene chiamato metodo di Eulero esplicito.

\section{Equazioni differenziali ordinarie}
\subsection{Richiamo sulle derivate}
Sia $ I $ un intervallo non degenere, cio\`e sia $ I $ in una delle seguenti forme:
\begin{itemize}
\item $ I = (a, b) $;
\item $ I = [a, b) $;
\item $ I = (a, b] $;
\item $ I = [a, b] $; 
\end{itemize}

con $ a, b \in \overline{\mathbb{R}} \defeq \mathbb{R} \cup \{ - \infty, + \infty \} $ tali che $ a < b $. Inoltre sia $ d \in \mathbb{N} $. Una funzione $ v: I \to \mathbb{R}^{d} $ si dice derivabile in $ t \in I $ se esiste

\[ v'(t) = \lim\limits_{s \to t} \frac{v(s) - v(t)}{s - t} \]

Dove definito, si pone, $ \forall\ t \in I $

\[
\begin{cases}
v^{(0)}(t) = v(t) \\
v^{(k + 1)}(t) = (v^{(k)})' (t) 
\end{cases}
\]

\subsection{Equazione differenziale ordinaria esplicita}
Siano $ d, k \in \mathbb{N} $, $ \Omega \subseteq \mathbb{R} \times \mathbb{R}^{kd} $ un insieme aperto e connesso.

\begin{itemize}
\item Una funzione $ u: I \to \mathbb{R}^{d} $ si dice soluzione dell'equazione differenziale ordinaria esplicita se

\[
u^{(k)} = f \left( \cdot, u^{(0)}, \dotsc, u^{(k - 1)} \right)
\]

cio\`e se $ \forall\ t \in I, \exists\ u^{(0)}(t), \dotsc, u^{(k)}(t) $ e 

\begin{equation}	\label{eq:EDO}
u^{(k)}(t) = f \left( t, u^{(0)}(t), \dotsc, u^{(k - 1)}(t) \right)
\end{equation}

$ d $ si dice dimensione dell'equazione differenziale ordinaria e $ k $ \`e il suo ordine.

\item $ (\ref{eq:EDO}) $ si dice autonomo se $ \exists\ \Omega_{0} \subseteq \mathbb{R}^{kd} $ e $ f_{0}: \Omega_{0} \to \mathbb{R}^{d} $ tale che $ \Omega = \mathbb{R} \times \Omega_{0} $ e $ \forall\ t \in \mathbb{R}, z \in \Omega_{0} $ si ha che $ f(t, z) = f_{0} (z) $;
\item $ (\ref{eq:EDO}) $ si dice lineare se 

\[ f(t, z) = \sum\limits_{i = 0}^{k - 1} a_{i} (t) z_{i} + b(t) \]

dove $ a_{0}, \dotsc, a_{k - 1}: \mathbb{R} \to \mathbb{R}^{d \times d} $ e $ b: \mathbb{R} \to \mathbb{R}^{d} $. Inoltre se $ b \equiv 0 $ si dice omogeneo, altrimenti non omogeneo.
\end{itemize}

\subsection{Qualche esempio}
\noindent
\begin{enumerate}
\item Dato $ \lambda \in \mathbb{R} $ si consideri $ u' = \lambda u $ in $ \mathbb{R} $. Tale equazione differenziale ha dimensione 1, ordine 1, \`e autonomo, lineare e omogeneo. Le soluzioni assumono la seguente forma:

\[ u(t) = C \exp(\lambda t) \]

con $ C \in \mathbb{R} $.

\begin{itemize}
\item Se $ \lambda > 0 $ si parla di crescita esponenziale ed \`e facilmente calcolabile con il metodo di Eulero esplicito;
\item Se $ \lambda < 0 $ si parla di decrescita esponenziale e si riscontrano problemi nel calcolo con il metodo di Eulero esplicito.
\end{itemize}

\item Un modello di crescita pi\`u flessibile \`e l'equazione di Verhulst

\[ u' = \lambda u \left( 1 - \frac{u}{k} \right) \]

che ha dimensione 1, ordine 1, \`e autonoma ma non \`e lineare. La soluzione generale \`e 

\[ u(t) = \frac{K C \exp (\lambda t)}{K + C (\exp (\lambda t) - 1)} \]

\item Dato un campo vettoriale $ f: \mathbb{R}^{3} \to \mathbb{R}^{3} $ la seconda legge di Newton pu\`o assumere la seguente forma in $ \mathbb{R} $:

\[ u'' = f(u) \]

che ha dimensione 3, ordine 2, \`e autonomo e in generale non \`e lineare. Il sottocaso lineare $ f(z) = - kz $, con $ z \in \mathbb{R}^{3} $, $ k \in \mathbb{R}^{d \times d} $ si dice oscillatore armonico;

\item Si consideri l'oscillatore armonico in una dimensione e con $ k  = 1 $:

\[ u'' = - u \]

Introducendo la nuova variabile $ v = u' $ si pu\`o riscrivere l'equazione con il seguente sistema

\[
\begin{cases}
u' = v \\
v' = -u
\end{cases} \iff \begin{pmatrix}
	u \\
	v \\
\end{pmatrix} ' = \begin{pmatrix}
	 0 & 1 \\
	-1 & 0 \\
\end{pmatrix} \begin{pmatrix}
	u \\
	v \\
\end{pmatrix}
\]

e con $ z = u + iv \in \mathbb{C} $ il problema diventa

\[ z' = -i z \]

poich\'e $ -i(u + iv) = -i u + v $. Questo corrisponde all'esempio $ 1. $ in $ \mathbb{C} $ con $ \lambda = -i $.
\end{enumerate}

\section{Problemi ai valori iniziali}
Le applicazioni e le soluzioni generali degli esempi nel paragrafo precedente suggeriscono di porre ulteriori condizioni per individuare una soluzione di un'equazione differenziale ordinaria.

\subsection{Problema ai valori iniziali}
Siano $ d, k \in \mathbb{N} $, $ \Omega \subseteq \mathbb{R} \times \mathbb{R}^{kd} $ dominio aperto e connesso. Sia $ f: \Omega \to \mathbb{R}^{d} $, $ (t_{0}, v_{0}, \dotsc, v_{k-1}) \in \Omega $, $ t_{0} < T $ e $ I = [t_{0}, T] $.

Una funzione $ u: I \to \mathbb{R}^{d} $ si dice soluzione di $ u^{(k)} = f(\cdot, u^{(0)}, \dotsc, u^{(k-1)}) $ con $ u^{(i)} (t_{0}) = v_{i} $ con $ i = 0, \dotsc, k - 1 $ se:
\begin{enumerate}
\item $ u $ \`e derivabile con continuit\`a $ k $ volte in $ I $ e $ \forall\ t \in I, \left( t, u^{(0)}(t), \dotsc, u^{(k-1)}(t) \right) \in \Omega $;
\item $ u^{(i)} (t_{0}) = v_{i} $ per $ i = 0, \dotsc, k - 1 $;
\item $ \forall\ t \in I, u^{(k)}(t) = f \left( t, u(t), \dotsc, u^{(k-1)}(t) \right) $.
\end{enumerate}

Introducendo nuove variabili, cio\`e aumentando $ d $, ci si pu\`o sempre  ridursi al caso $ k = 1 $. Da ora in poi si considerer\`a $ k = 1 $.

\subsection{Un esempio di non-unicit\`a}
Si consideri in $ [0, +\infty) $

\[ \begin{cases}
u' = 3 u^{\frac{2}{3}} \\
u(0) = 0
\end{cases}
\]

cio\`e $ \Omega = \mathbb{R} \times \mathbb{R}^{+}_{0} $, $ t_{0} = 0 $, $ v = 0 $, $ f(z) = 3 z^{\frac{2}{3}} $. Si osserva che
\begin{itemize}
\item $ u_{1}(t) \equiv 0 $
\item $ u_{2}(t) = t^{3} $
\end{itemize}
sono soluzioni del problema considerato. Si noti inoltre che

\[ \lim\limits_{z \to 0^{+}} f'(z) = \lim\limits_{z \to 0^{+}} 2 z^{-\frac{1}{3}} = \infty \]

\subsection{Un criterio di unicit\`a (per $ k = 1 $)}
Nelle ipotesi di \S 3.1 si supponga che $ k = 1 $. Se $ [f(t, z_{1}) - f(t, z_{2})] \cdot [z_{1} - z_{2}] \le l \vert z_{1} - z_{2} \vert^{2}, \forall\ (t, z_{1}), (t, z_{2}) \in \Omega $, dove
\begin{itemize}
\item $ \cdot $ \`e il prodotto scalare in $ \mathbb{R}^{d} $
\item $ l \in \mathbb{R} $
\end{itemize}

allora due soluzioni $ u_{1}, u_{2}: I \to \mathbb{R} $ di $ (\ref{eq:PVI}) $ coincidono in $ \mathcal{C}(I, \mathbb{R}^{d}) $.

\begin{proof}
$ \forall\ t \in I $ si ha

\begin{dmath*}
{ \frac{\mathrm{d}}{\mathrm{d}t} \left[ \frac{1}{2} \vert u_{1}(t) - u_{2}(t) \vert^{2} \right] } = { \left( u_{1}(t) - u_{2}(t) \right) \cdot \left( u_{1}' (t) - u_{2}' (t) \right) } = \\ { [ f \left( t, u_{1}(t) \right) - f \left( t, u_{2}(t) \right) ] \cdot [u_{1}(t) - u_{2}(t)] } \le { l \vert u_{1}(t) - u_{2} (t) \vert^{2} }
\end{dmath*}

Quindi

\[ d(t) \defeq \frac{1}{2} e^{-2lt} \vert u_{1}(t) - u_{2}(t) \vert^{2} \]

soddisfa

\[ d'(t) \le -l e^{-2lt} \vert u_{1}(t) - u_{2}(t) \vert^{2} + e^{-2lt} l \vert u_{1}(t) - u_{2}(t) \vert^{2} = 0 \]

da cui

\[ d(s) = \underbrace{d(0)}_{= 0} + \int\limits_{0}^{s} \underbrace{d'(t)}_{\le 0} \, \mathrm{d}t \]

e quindi, in $ I $

\[ d(t) \equiv 0 \implies u_{1} \equiv u_{2}  \]
\end{proof}

\section{Metodi numerici e condizionamento}
\subsection{Metodi numerici}

Un metodo numerico \`e una "mappa" del tipo

\begin{center}
(problema continuo, parametro) $ \mapsto $ problema discreto
\end{center}

Ad esempio in \S 1 abbiamo associato al problema continuo $ \ref{eq:PVI} $ e al parametro $ N \in \mathbb{N} $ il problema discreto $ (\ref{eq:EE}) $ con $ t_{n} = t_{0} + n \tau $ e $ \tau = \frac{T - t_{0}}{N} $. Si noti che i $ t_{i} $ sono tutti equidistanti. Se non lo fossero, come in metodi che verranno affrontati successivamente, al posto di un parametro si dovrebbe inserire un vettore di punti che formano la griglia dei tempi. Anche questa soluzione non \`e generale poich\'e alcuni metodi prevedono un ordine preciso di uso dei tempi $ t_{i} $. Per ora saranno considererati solo metodi con griglia equidistante.

I metodi "numerici" sono un modello dei metodi "computazionali".

\subsection{Convergenza}
Per valutare la bont\`a  di un metodo numerico \`e interessante bilanciare costo e qualit\`a: nel caso di \S 1, ad esempio, sarebbe il bilanciamento di $ N $, dato che il numero dei passi \`e uguale al numero di valutazioni della $ f $ e quindi \`e approssimabile al costo computazionale, oppure  $ \max\limits_{n = 0, \dotsc, N} \vert u(t_{n})  - U_{n} \vert $. In particolare ci interessano le stime del tipo $ \max\limits_{n = 0, \dotsc, N} \vert u(t_{n})  - U_{n} \vert \le C N^{-p} $, con $ p > 0 $, che qualifica anche la velocit\`a di convergenza.

\subsection{Buona posizione e buon posizionamento}
I problemi continui e discreti dovrebbero essere ben posti, cio\`e, secondo Hadamard:
\begin{enumerate}
\item deve esistere almeno una soluzione;
\item deve esistere al pi\`u una soluzione;
\item la soluzione deve dipendere in modo continuo dai dati.
\end{enumerate}

Nel caso di $ (\ref{eq:PVI}) $ i dati sono $ f $ e $ v $. Inoltre, il problema discreto che viene "risolto" sul computer con aritmetica finita dovrebbe essere in particolare ben condizionato, cio\`e:
\begin{enumerate}
\item[4.] piccole perturbazioni nei dati producono piccole perturbazioni nella soluzione.
\end{enumerate}

Poich\'e il problema discreto discende dal problema continuo e si spera che lo "diventi" per $ N \to +\infty $, anche il problema continuo dovrebbe essere ben condizionato. Si noti che il punto 2 pu\`o essere riscritto nel seguente modo:
\begin{enumerate}
\item[2b.] nessuna perturbazione nei dati, quindi nessuna perturbazione nella soluzione.  
\end{enumerate}

In altre parole, prima di comprendere il punto 3 bisogna comprendere il punto 2.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

										MANCANO LE LEZIONI 5 E 6!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Consistenza e regolarit\`a}
\section{Preliminari}
\subsection{Evoluzione}
Sia $ \Omega \subseteq \mathbb{R} \times \mathbb{R}^{d} $, $ f: \Omega \to \mathbb{R}^{d} $ tale che $ \forall\ (t_{0}, v) \in \Omega $ il problema

\begin{equation}	\label{eq:probevol}
\begin{cases}
u' = f(\cdot, u) \\
u(t_{0}) = v
\end{cases}
\end{equation}

ha un'unica soluzione massimale $ u(t_{0}, v) : [t_{0}, T(t_{0}, v)] \to \mathbb{R}^{d} $ derivabile in $ t_{0} $. Qui massimale significa che se $ \tilde{u} : [t_{0}, \tilde{T}] \to \mathbb{R}^{d} $ \`e un'altra soluzione allora $ \tilde{T} < T(t_{0}, v) $ e $ \tilde{u} = u $ su $ [t_{0}, \tilde{T}) $

Si pone quindi, $ \forall\ t \in [t_{0}, T(t_{0}, v)] $

\[ \varphi(t, t_{0}) v = u_{(t_{0}, v)} (t) \]

chiamata evoluzione di $ f $.

\begin{oss}
\noindent
\begin{enumerate}
\item $ \varphi(t_{0}, t_{0}) v = v $;
\item Se $ t_{0} \le t_{1} \le t_{2} \le t_{3} < T(t_{0}, v) $ allora $ \varphi(t_{3}, t_{2}) \varphi(t_{2}, t_{1}) v = \varphi(t_{3}, t_{1}) v $;
\item $ \lim\limits_{\tau \to 0^{+}} \frac{\mathrm{d}}{\mathrm{d} \tau} \varphi (t + \tau, t)v = \lim\limits_{\tau \to 0^{+}} \frac{\varphi(t + \tau, t)v - \varphi(t, t)v}{\tau} = f(t, v) $
\end{enumerate}
\end{oss}

\subsection{Metodi a un passo}

Siano $ \Omega, f $ e $ \varphi $ come nel capitolo precedente. Un metodo ad un passo associa a $ f $ una funzione incremento $ F = F(t, z, \tau), \forall\ (t, z) \in \Omega, \tau \in [0, \tau(t, z)] $ con $ \tau(t, z) > 0 $. Posto

\[ \Phi (t_{1}, t_{2}) v = v + (t_{2} - t_{1}) F(t_{1}, v, t_{2} - t_{1}) \]

una soluzione approssimata di $ (\ref{eq:probevol}) $ in \S 7.1 sulla griglia

\[ t_{0} < t_{1} < \dotsb < t_{N} \]

\`e data da 

\[
\begin{cases}
U_{n+1} = \Phi(t_{n + 1}, t_{n}) U_{n} \\
U_{0} = v
\end{cases}
\]

\begin{oss}
\noindent
\begin{enumerate}
\item $ \Phi(t_{n+1}, t_{n}) v $ vuole approssimare $ \varphi(t_{n + 1}, t_{n}) $
\item Per il calcolo di $ U_{N} $ non \`e necessario memorizzare $ U_{0}, \dotsc, U_{N - 2} $
\item $ \Phi (t_{0}, t_{0}) v = v $ ma in generale non si ha, per $ 0 \le n \le k \le l \le N $

\[ \Phi(t_{l}, t_{k}) \Phi(t_{k}, t_{n}) v  = \Phi(t_{l}, t_{n}) v \]
\end{enumerate}
\end{oss}

\begin{es}
Per il metodo di Eulero esplicito si ha, con $ (t, z) \in \Omega, T > 0 $

\[ F(t, z, \tau) = f(t, z) \]
\end{es}

\subsection{Teorema di Taylor}

Sia $ I $ intervallo, $ r \in \mathbb{N} $ e $ u \in \mathcal{C}^{r} (I, \mathbb{R}^{d}) = \{ w : I \to \mathbb{R}^{d} : w^{(0)}, \dotsc, w^{(r)} \text{ esistono e sono continue in } I \} $. Allora

\[ \underbrace{u(s)}_{\in I} = \sum\limits_{k = 0}^{r - 1} \frac{u^{(k)}(t)}{k!} (s - t)^{k} + \frac{1}{(k - 1)!} \int\limits_{t}^{s} u^{(r)} (\xi) (s - t)^{r} \, \mathrm{d}\xi \]

\begin{proof}
Analisi
\end{proof}

\subsection{Simboli di Landau}

Sia $ f: [0, \tau^{\ast}] \to \mathbb{R}^{d} $ e $ b: [0, \tau^{\ast}] \to \mathbb{R}^{\ast} = \mathbb{R} \setminus \{ 0 \} $.

\begin{itemize}
\item $ f = O (b) $ per $ \tau \to 0 $ se $ \exists\ C \ge 0, \tau_{0} \in (0, \tau^{\ast}) : \vert f(\tau) \vert \le C b(\tau) $
\item $ f = o(b) $ per $ \tau \to 0 $ se $ \lim\limits_{\tau \to 0^{+}} \frac{\vert f(\tau) \vert}{b(\tau)} = 0 $
\end{itemize}

\begin{es}
\noindent
\begin{itemize}
\item $ u $ continua in $ t \implies u(t + \tau) = u(t) + o(1) $ per $ \tau \to 0 $;
\item $ u $ lipschitziana $ \implies u(t + \tau) = u(t) + O(\tau) $;
\item $ u $ \`e derivabile in $ t \implies u(t + \tau) = u(t) + u'(t) \tau + o(\tau) $
\end{itemize}
\end{es}

\section{Consistenza di metodi a un passo}
\subsection{Definizione di consistenza}

Un metodo ad un passo con $ \Phi $ e $ F $ si dice consistente per $ u' = f(\cdot, u) $ se una delle seguenti condizioni equivalenti \`e soddisfatta:

\begin{enumerate}
\item $ \forall\ (t, z) \in \Omega, \lim\limits_{\tau \to 0^{+}} \frac{\mathrm{d}}{\mathrm{d} \tau} \Phi(t + \tau, t)z = f(t, z) $
\item $ \forall\ (t, z) \in \Omega, \lim\limits_{\tau \to 0} F(t, z, \tau) = f(t, z) $
\item $ \forall\ (t, z) \in \Omega, \varepsilon(t, z, \tau) \defeq \varphi(t + \tau, t)z - \Phi(t + \tau, t)z = o(\tau) $ per $ \tau \to 0 $
\end{enumerate}

Si osserva che $ \varepsilon(t, z, \tau) \defeq \varphi(t + \tau, t)z - [z + \tau F(t, z, \tau)] $ misura per quanto la soluzione esatta non \`e una soluzione del metodo.

\begin{proof}
\noindent
\begin{itemize}
\item[$ 1. \implies 2. $] $ \lim\limits_{\tau \to 0} F(t, z, \tau) = \lim\limits_{\tau \to 0} \frac{\Phi (t + \tau, t)z - z}{\tau} = \lim\limits_{\tau \to 0^{+}} \Phi(t + \tau, t)z \stackrel{1.}{=} f(t, z) $
\item[$ 2. \implies 3. $] $ \varepsilon(t, \tau, z) = \varphi(t + \tau, t) z - \Phi(t + \tau, t) z = z + \int\limits_{t}^{t + \tau} f(s, \varphi(t + s)) \, \mathrm{d}s - {[z + \tau F(t, z, \tau)]} = \int\limits_{t}^{t + \tau} f(s, \varphi(t + s)) - F(t, z, \tau) \, \mathrm{d}s = {\underbrace{\int\limits_{t}^{t + \tau} \underbrace{f(s + t, \underbrace{\varphi(t + s, t)z}_{= z + o(1) \text{ per } \tau \to 0}) - f(t, z)}_{= o(1)} \, \mathrm{d}s}_{= o(\tau)}} + {\underbrace{\int\limits_{t}^{t + \tau} \underbrace{f(t, z) - F(t, z, \tau)}_{= o(1) \text{ per } \tau \to 0} \, \mathrm{d}s}_{= o(\tau)}} $
\item[$ 3. \implies 1. $] $ \lim\limits_{\tau \to 0} \frac{\mathrm{d}}{\mathrm{d} \tau} \Phi(t + \tau, t)z = \lim\limits_{\tau \to 0} \frac{\Phi(t + \tau, t)z - z}{\tau} = \lim\limits_{\tau \to 0} \frac{\varphi(t + \tau, t)z - z}{\tau} - \frac{\overbrace{\varepsilon(t , z, \tau)}^{o(\tau)}}{\tau} = f(t, z) + 0 $
\end{itemize}
\end{proof}

\subsection{Consistenza del metodo di Eulero esplicito}
Dato $ (t, z) \in \Omega $, si scrive 

\[ u(t + \tau) = \Phi(t + \tau, t) z \]

Si ha, per $ \tau \to 0 $, che $ \varepsilon_{EE} (t, z) = u(t + \tau) - [u(t) + \tau f(t, u(t))] = u(t + \tau) - u(t) - \tau u'(t) = \int\limits_{t}^{t + \tau} u'(s) \, \mathrm{d}s - \tau u'(t) = \underbrace{\int\limits_{t}^{t + \tau} \underbrace{u'(s) - u'(t)}_{= o(1) \text{ se $ u $ continua in } t} \, \mathrm{d}s}_{O(\vert s - t \vert) = O(\tau^{2})} = o(\tau) $

\section{Un metodo di ordine superiore}
\subsection{Un ordine di pi\`u per $ \varepsilon $. L'errore di consistenza}
In \S 8.2 si \`e osservato che l'errore di consistenza di Eulero esplicito \`e di $ O(\tau^{2}) $ per $ \tau \to  0$ se la soluzione di $ u'= f(\cdot u) $ \`e due volte derivabile con continuit\`a . Si cerca di derivare un metodo per cui l'errore di consistenza pu\`o soddisfare $ O(\tau^{3}) $ per $ \tau \to 0 $. A questo scopo si osserva che

$ u(t + h) - u(t - h) = u(t) + h u'(t) + \frac{1}{2} h^{2} u''(t) + \frac{1}{6} h^{3} u^{(3)} (t^{+}) - [u(t) - h u'(t) + \frac{1}{2} h^{2} u''(t) - \frac{1}{6} h^{3} u^{(3)} (t^{-})] = 2h u'(t) + O(t^{3}) $ 

ovvero

\begin{equation}
u'(t) = \frac{u(t + h) - u(t - h)}{2h} + O(h^{3})
\end{equation} 

Sia $ t_{0} < t_{1} < \dotsb < t_{N} = T $ uan griglia e $ \tau_{n} = t_{n + 1} - t_{n} $, con $ n = 0, \dotsc, N - 1 $. Ponendo $ \tau_{n} = \frac{h}{2} $ conduce a $ \frac{u(t_{n + 1}) - u(t_{n})}{\tau_{n}} = u' \left( t_{n} + \frac{\tau_{n}}{2} \right) + O(\tau_{n}^{2}) = f(t_{n} + \frac{\tau_{n}}{2}, u \left( t_{n} + \frac{\tau_{n}}{2} \right)  + O(\tau_{n}^{2}) $. Il problema \`e che $ t_{n} + \frac{\tau_{n}}{2} $ non \`e un punto della griglia, quindi approssimando $ u \left( t_{n} + \frac{\tau_{n}}{2} \right) $ con il metodo di Eulero esplicito con passo $ \frac{\tau_{n}}{2} $ si ottiene 

\[ u \left( t_{n} + \frac{\tau_{n}}{2} \right) = u(t_{n}) + \frac{\tau_{n}}{2} f(t_{n}, u(t_{n})) + O(\tau_{n}^{2}) \]

e, supponendo che $ f = f(t, z) $ \`e Lipschitz rispetto a $ z $, si ottiene

\[ f \left( t_{n} + \frac{\tau_{n}}{2}, u \left(t_{n} + \frac{\tau_{n}}{2} \right) \right) = f(t_{n} + \frac{\tau_{n}}{2}, u(t_{n} + \frac{\tau_{n}}{2} f(t_{n}, u(t_{n}) ) + O(\tau_{n}^{2})  \]

Riassumendo, si ha sotto le ipotesi fatte, per $ \tau \to 0 $

\[ \frac{u(t_{n + 1}) - u(t_{n})}{2 \tau_{n}} = f \left( t_{n} + \frac{\tau_{n}}{2}, u(t_{n}) + \frac{\tau_{n}}{2} f(t_{n}, u(t_{n}) \right) + O(\tau_{n}^{2} \]

Questo suggerisce il cosiddetto metodo di Eulero modificato

\[
\begin{cases}
U_{0} = v \\
U_{n + 1} = U_{n} + \tau f \left( t_{n} + \frac{\tau_{n}}{2}, U_{n} + \frac{\tau_{n}}{2} f(t_{n}, U_{n}) \right)	 & n = 0, \dotsc, N - 1
\end{cases}
\]

Si noti che qui la funzione $ f $ viene valutato due volte per passo. 

\subsection{Ordine sperimentale dell'errore di Eulero modificato}
In un problema dove $ f $ \`e Lipschitz rispetto a  $ z $ e $ u $ tre volte derivabile con continuit\`a si osserva effettivamente che nel tempo finale $ T $

\[ \vert U_{n} - u(T) \vert \approx \tau^{2} = \frac{1}{N^{2}} \]

\begin{center}
\begin{tabular}{c|c|c}
	Metodo & Costo & Errore \\
\hline
	E. E. & $ N $ & $ \approx \frac{1}{N} $ \\
\hline
	E. M. & $ 2N $ & $ \approx \frac{1}{4N^{2}} $ \\
\end{tabular}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Velocit\`a di convergenza e dipendenza dalla regolarit\`a}
\subsection{Eulero esplicito vs. Eulero modificato}

Nella seguente tabella viene mostrato il costo in termini di valutazion edella $ f $ dei metodi di Eulero esplicito ed Eulero modificato per raggiungere un dato livello di errore relativo (\S 9.3)

\begin{tabular}{c|c|c|c|c}
	Tolleranza & $ 10\% $ & $ 1\% $ & $ 0.1\% $ & $ 0.01\% $ \\
\hline
	E.E. & 8 & 64 & 512 & 8192 \\
\hline
	E.M. & 2 & 8 & 32 & 128 \\
\hline
	Raddoppio & 4 & 8 & 16 & 64 \\
\end{tabular}

Questo viene illustrato anche nel bilancio qualit\`a-costo in scala $ \log-\log $

\begin{center}
\begin{figure}[H]
\begin{tikzpicture}
	\draw[->] (-1, 0) -- (5, 0) node[right] {$ \log N $};
	\draw[->] (0, -5) -- (0, 1) node[above] {$ \log \mathop{err} $};
	\filldraw (1, 0) circle (1pt) node[above] {$ 10^{1} $};
	\filldraw (2, 0) circle (1pt) node[above] {$ 10^{2} $};
	\filldraw (3, 0) circle (1pt) node[above] {$ 10^{3} $};
	\filldraw (4, 0) circle (1pt) node[above] {$ 10^{4} $};
	\filldraw (0, -1) circle (1pt) node[left] {$ 10^{-1} $};
	\filldraw (0, -2) circle (1pt) node[left] {$ 10^{-2} $};
	\filldraw (0, -3) circle (1pt) node[left] {$ 10^{-3} $};
	\filldraw (0, -4) circle (1pt) node[left] {$ 10^{-4} $};
	\draw (1, 0) -- (4.5, -3.5);
	\draw (1, 0) -- (3.25, -4.5);
\end{tikzpicture}

\caption{$ \mathop{err} \approx C N^{-p} \iff \log \mathop{err} \approx \log C - p \log N $}
\end{figure}
\end{center}

\subsection{Impatto della regolarit\`a}
Si consideri il problema

\[
\begin{cases}
u' = t^{p} u & \text{ in } (0, 1) \\
u(1) = \exp \left( \frac{1}{1 + p} \right) 
\end{cases}
\]

con $ p > -1 $. La soluzione \`e $ u(t) = \exp \left( \frac{t^{p + 1}}{p + 1} \right) $ per $ t \ge 0 $. Posto $ f(t, z) = t^{p} z $, con $ z \in \mathbb{R} $ e $ t > 0 $ si ha il seguente grafico:

\begin{center}
\begin{figure}[H]
\begin{tikzpicture}
	\draw[->] (-1, 0) -- (2, 0) node[right] {$ z $};
	\draw[->] (0, -1) -- (0, 3) node[right] {$ f(2, z) $};
	\filldraw (1, 0) circle (1pt) node[below] {$ 1 $};
	\filldraw (0, 0) circle (1pt) node[below left] {$ 0 $};

    \draw[domain=0:1, dashed, smooth] plot (\x, {2*\x^0.4});
    \draw[domain=0.05:1, smooth] plot (\x, {2*\x^(-0.1)});
    \draw[domain=0:1, dotted, smooth] plot (\x, {2*\x});
    \draw[domain=0:1, smooth] plot (\x, {2*\x^10});
\end{tikzpicture}

\caption{Grafici di $ f(2, z) $ con $ p = 1 $ (puntinato), $ p = 0.4 \in (0, 1) $ (tratteggiato), $ p = 10 \gg 1 $ (grafico inferiore) e $ p = -0.7 \in (-1, 0) $ (grafico superiore)}
\end{figure}
\end{center}

Si osserva numericamente che:
\begin{enumerate}
\item con l'aumentare di $ p \gg 1 $ l'ordine del metodo si osserva pi\`u tardi, cio\`e per $ N $ grandi;
\item per $ p \in (0, 1) $ il metodo di Eulero modificato mostra solo un ordine di convergenza di $ p + 1 < 2 $. Una "spiegazione" \`e data dalla barriera dell'errore di consistenza dell'ultimo passo $ \approx \tau^{3} \tau^{p - 2} = \tau^{p + 1} $;
\item per $ p \in (-1, 0) $ entrambi i metodi mostrano solo l'errore di convergenza $ 1 + p < 1 $. Una "spiegazione" \`e data da $ \tau^{2} \tau^{p - 1} = \tau^{p + 1} $.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

										MANCANO LE LEZIONI 11 E 12!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Metodi di Runge-Kutta}
\subsection{Definizione}
Un metodo di Runge-Kutta (RK) a $ s \in \mathbb{N} $ stadi \`e determinato da:

\begin{itemize}
\item $ A = (a_{ij})_{i, j = 1, \dotsc, s} \in \mathbb{R}^{s \times s} $
\item $ b = (b_{1}, \dotsc, b_{s})^{T} \in \mathbb{R}^{s} $
\item $ c = (c_{1}, \dotsc, c_{s})^{T} \in \mathbb{R}^{s} $ 
\end{itemize}

e associa a una funzione $ f: \Omega \subseteq \mathbb{R} \times \mathbb{R}^{d} \to \mathbb{R}^{d} $ la funzione

\[ F(t, z, \tau) = \sum\limits_{i = 1}^{s} b_{i} k_{i} \]

dove gli stadi $ k_{1}, \dotsc, k_{s} \in \mathbb{R}^{d} $ sono "la" soluzione del sistema non lineare

\begin{equation}	\label{eq:ki}
k_{i} = f \left( t + c_{i} \tau, z + \tau \sum\limits_{j = 1}^{s} a_{ij} k_{j} \right)
\end{equation}

con $ i = 1, \dotsc, s $. I parametri si rappresentano solitamente con il cosiddetto schema di Butcher

\begin{center}
\begin{tabular}{c|ccc}
                  &   &       & \\
$ \underline{c} $ &   & $ A $ & \\
				  &   &       & \\
\hline
				  &   & $ \underline{b}^{T} $ & \\
\end{tabular}
\end{center}

Il metodo si dice esplicito se $ a_{ij} = 0 $ per $ j \ge i $, ovvero $ A = \begin{pmatrix}
	     0 &      0 & \ldots &      0 \\
	  \ast & \ddots & \ddots & \vdots \\
	\vdots & \ddots & \ddots &      0 \\
	  \ast & \ldots &   \ast &      0 \\
\end{pmatrix} $. In questo caso, $ (\ref{eq:ki}) $ di riduce a:
\begin{itemize}
\item $ k_{1} = f(t + c_{1} \tau, z) $
\item $ k_{2} = f(t + c_{2} \tau, z + \tau a_{21} k_{1}) $
\item $ k_{s} = f \left( t + c_{s} \tau, z + \tau \sum\limits_{j = 1}^{s-1} a_{sj} k_{j} \right) $
\end{itemize}

\subsection{Esempi}
\begin{enumerate}
\item Eulero esplicito:
\[ F(t, z \tau) = f(t, z) \]

\begin{center}
\begin{tabular}{c|c}
$ 0 $ & $ 0 $ \\
\hline
	  & $ 1 $ \\
\end{tabular}
\end{center}
\item Eulero modificato: 
\[ F(t, z \tau) = f \left( t + \frac{\tau}{2}, z + \frac{\tau}{2} f(t, z) \right) \]

\begin{center}
\begin{tabular}{c|cc}
          $ 0 $ &           $ 0 $ & $ 0 $ \\
$ \frac{1}{2} $ & $ \frac{1}{2} $ & $ 0 $ \\
\hline
                &           $ 0 $ & $ 1 $ \\

\end{tabular}
\end{center}
\item Eulero implicito:
\[ z^{+} = z + \tau f(t + \tau, z^{+}) \iff \frac{z^{+} - z}{\tau} = \underbrace{f(t + \tau, z^{+})}_{\eqdef k_{1}} \iff k_{1} = f(t + \tau, z + \tau k_{1}) \]

\begin{center}
\begin{tabular}{c|c}
$ 1 $ & $ 1 $ \\
\hline
	  & $ 1 $ \\
\end{tabular}
\end{center}
\end{enumerate}

\subsection{Consistenza}
Un metodo Runge-Kutta definito da $ (A, \underline{b}, \underline{c}) $ \`e consistente $ \forall\ f $ continua se e solo se $ \sum\limits_{i = 1}^{s} b_{i} = 1 $.

\begin{proof}
Essendo un metodo a un passo si pu\`o usare \S 8.1 (2). Nel caso di $ \tau = 0 $, $ (\ref{eq:ki}) $ si riduce a

\[ k_{i} = f \left(t + c_{i} 0, z + 0 \sum\limits_{j = 1}^{s} a_{ij} k_{j} \right) = f(t, z) \]

$ \forall\ i = 1, \dotsc, s $ da cui $ F(t, z, 0) = \sum\limits_{i = 1}^{s} b_{i} k_{i} = \left( \sum\limits_{i = 1}^{s} b_{i} \right) f(t, z) $. Se il metodo \'e consistente allora $ F(t, z, 0) = f(t, z) $ e $ f(t, z) \ne 0 $ implica $ \sum\limits_{i = 1}^{s} b_{i} = 1 $. Viceversa, se $ \sum\limits_{i = 1}^{s} b_{i} = 1 $ e se $ k_{i} = k_{i} (t, z) $ sono continui in $ (t, z) $, allora vale \S 8.1 (2)  e il metodo definito da $ (A, \underline{b}, \underline{c}) $ \`e consistente.
\end{proof}
\end{document}
