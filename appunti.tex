\documentclass[hidelinks, 10pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{xcolor}
\usepackage{blindtext}
\usepackage{listings}
\usepackage{float}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{cancel}
\usepackage{breqn}
\usepackage{verbatim}
\usepackage{mathtools}
\usepackage{epsfig}
\usepackage{epstopdf}
\usepackage{titling}
\usepackage{url}
\usepackage{array}
\usepackage{tikz}
\usepackage[a4paper]{geometry}

\usetikzlibrary{arrows, automata, backgrounds, calendar, chains, matrix, mindmap, patterns, petri, shadows, shapes.geometric, shapes.misc, spy, trees}

\author{Andreas Veeser}
\date{A.A. 2017-2018}
\title{Calcolo numerico 2}

\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\Mat}{Mat}

\begin{document}
\providecommand{\defeq}{\vcentcolon=}
\providecommand{\eqdef}{=\vcentcolon}
\providecommand{\compl}[1]{\prescript{c}{}{#1}}
\providecommand{\refsec}[1]{\S \ref{section:#1}}
\theoremstyle{plain}
\newtheorem{thm}{Teorema}[]

\theoremstyle{definition}
\newtheorem{defn}[]{Definizione}
\newtheorem{prop}[]{Proposizione}
\newtheorem{cor}[]{Corollario}
\newtheorem{lem}[]{Lemma}
\newtheorem{oss}[]{Osservazione}
\newtheorem{nota}[]{Nota}
\newtheorem{es}[]{Esempio}
\newtheorem{ex}[]{Esercizio}

\renewcommand{\thesection}{\arabic{section}}

\maketitle

\chapter{Introduzione}
\section{Discretizzazione di un problema ai valori iniziali}	\label{section:1}
\subsection{Problema ai valori iniziali}
Dati:
\begin{itemize}
\item $ t_{0} \in \mathbb{R} $ tempo iniziale;
\item $ T \in \mathbb{R} $ con $ T > t_{0} $ tempo finale;
\item $ I = [t_{0}, T] $ un intervallo;
\item $ f: I \times \mathbb{R} \to \mathbb{R} $ una funzione;
\item $ v \in \mathbb{R} $ valore iniziale;
\end{itemize}

l'obiettivo di un problema ai valori iniziali \`e quello di trovare $ u: I \to \mathbb{R} $ tale che
\[
\begin{cases}
u' = f(\cdot, u) \\
u(t_{0}) = v
\end{cases}
\]

o, meglio, $ \forall\ t \in I $

\begin{equation}	\label{eq:PVI}
\begin{cases}
u'(t) = f \left( t, u(t) \right) \\
u(t_{0}) = v
\end{cases}
\end{equation}

In generale $ u $ non \`e nota esplicitamente e quindi l'ottenere informazioni quantitative, come ad esempio $ u(T) $, richiede una risoluzione numerica. In $ (\ref{eq:PVI}) $ si celano un'infinit\`a di condizioni.

\subsection{Le griglie}
Un'equazione differenziale ordinaria (EDO) consiste di un numero infinito di condizioni, dato che $ t \in I $, linearmente indipendenti. Non si possono neanche verificare sul computer in tempo finito. Pertanto, si introduce una griglia (o \emph{mesh}) dell'intervallo $ I $:

\[ M_{N} = \{ t_{n} \defeq t_{0} + n \tau : n = 0, \dotsc, N \} \]

dove:
\begin{itemize}
\item $ N \in \mathbb{N} $ \`e il numero di passi;
\item $ \tau \defeq \frac{T - t_{0}}{N} $ \`e il passo temporale.
\end{itemize}

\begin{center}
\begin{figure}[H]
\begin{tikzpicture}
	\draw[->] (-4,0) -- (4,0) node[right] {$ t $};
	\filldraw (-3,0) circle (1pt) node[below] {$ t_{1} $};
	\filldraw (-2,0) circle (1pt) node[below] {$ t_{2} $};
	\filldraw (-1,0) circle (1pt) node[below] {$ t_{3} $};
	\fill (0,0) node[below] {$ \ldots $};
	\filldraw (1,0) circle (1pt) node[below] {$ t_{N - 2} $};;
	\filldraw (2,0) circle (1pt) node[below] {$ t_{N - 1} $};
	\filldraw (3,0) circle (1pt) node[below] {$ t_{N} $};
\end{tikzpicture}

\caption{Esempio di discretizzazione dell'asse delle $ t $. $ \tau $ \`e la distanza tra i vari nodi ed \`e costante.}
\end{figure}
\end{center}

\subsection{Sostituzione dell'operatore differenziale}
Data ad esempio $ t \in U_{N} $, neanche $ f \left( t, u(t) \right) = u'(t) $ \`e verificabile al computer poich\'e in generale

\[ u'(t) = \lim\limits_{h \to 0} \frac{u(t + h) - u(t)}{h} \]

coinvolge un numero infinito di operazioni. Se si usa l'approssimazione

\[ u'(t) \approx \frac{u(t + h) - u(t)}{h} \]

con $ t = t_{n} $ e $ h = t_{n + 1} - t_{n} = \tau $ si ottiene

\[
\begin{cases}
u(t_{0}) = v \\
\frac{u(t_{n + 1}) - u(t_{n})}{\tau} \approx f \left( t_{n}, u(t_{n}) \right)
\end{cases}
\]

Il pregio \`e che questo sistema \`e discreto, rispetto a $ (\ref{eq:PVI}) $.

Sostituendo $ \{ u(t_{n}) \}_{n = 0}^{N} $ con una successione finita incognita $ \{ U_{n} \} $ si ottiene

\begin{equation}	\label{eq:EE}
\begin{cases}
U_{0} = v \\
\frac{U_{n + 1} - U_{n}}{\tau} = f(t_{n}, U_{n})
\end{cases}
\end{equation}

Dal momento che $ \frac{U_{n + 1} - U_{n}}{\tau} = f(t_{n}, U_{n}) \iff U_{n + 1} = U_{n} + \tau f(t_{n}, U_{n}) $, gli $ U_{n} $ possono essere facilmente (persino velocemente) calcolati con un'interazione da $ U_{0} = v $. $ (\ref{eq:EE}) $ viene chiamato metodo di Eulero esplicito.

\section{Equazioni differenziali ordinarie}
\subsection{Richiamo sulle derivate}
Sia $ I $ un intervallo non degenere, cio\`e sia $ I $ in una delle seguenti forme:
\begin{itemize}
\item $ I = (a, b) $;
\item $ I = [a, b) $;
\item $ I = (a, b] $;
\item $ I = [a, b] $; 
\end{itemize}

con $ a, b \in \overline{\mathbb{R}} \defeq \mathbb{R} \cup \{ - \infty, + \infty \} $ tali che $ a < b $. Inoltre sia $ d \in \mathbb{N} $. Una funzione $ v: I \to \mathbb{R}^{d} $ si dice derivabile in $ t \in I $ se esiste

\[ v'(t) = \lim\limits_{s \to t} \frac{v(s) - v(t)}{s - t} \]

Dove definito, si pone, $ \forall\ t \in I $

\[
\begin{cases}
v^{(0)}(t) = v(t) \\
v^{(k + 1)}(t) = (v^{(k)})' (t) 
\end{cases}
\]

\subsection{Equazione differenziale ordinaria esplicita}
Siano $ d, k \in \mathbb{N} $, $ \Omega \subseteq \mathbb{R} \times \mathbb{R}^{kd} $ un insieme aperto e connesso.

\begin{itemize}
\item Una funzione $ u: I \to \mathbb{R}^{d} $ si dice soluzione dell'equazione differenziale ordinaria esplicita se

\[
u^{(k)} = f \left( \cdot, u^{(0)}, \dotsc, u^{(k - 1)} \right)
\]

cio\`e se $ \forall\ t \in I, \exists\ u^{(0)}(t), \dotsc, u^{(k)}(t) $ e 

\begin{equation}	\label{eq:EDO}
u^{(k)}(t) = f \left( t, u^{(0)}(t), \dotsc, u^{(k - 1)}(t) \right)
\end{equation}

$ d $ si dice dimensione dell'equazione differenziale ordinaria e $ k $ \`e il suo ordine.

\item $ (\ref{eq:EDO}) $ si dice autonomo se $ \exists\ \Omega_{0} \subseteq \mathbb{R}^{kd} $ e $ f_{0}: \Omega_{0} \to \mathbb{R}^{d} $ tale che $ \Omega = \mathbb{R} \times \Omega_{0} $ e $ \forall\ t \in \mathbb{R}, z \in \Omega_{0} $ si ha che $ f(t, z) = f_{0} (z) $;
\item $ (\ref{eq:EDO}) $ si dice lineare se 

\[ f(t, z) = \sum\limits_{i = 0}^{k - 1} a_{i} (t) z_{i} + b(t) \]

dove $ a_{0}, \dotsc, a_{k - 1}: \mathbb{R} \to \mathbb{R}^{d \times d} $ e $ b: \mathbb{R} \to \mathbb{R}^{d} $. Inoltre se $ b \equiv 0 $ si dice omogeneo, altrimenti non omogeneo.
\end{itemize}

\subsection{Qualche esempio}
\noindent
\begin{enumerate}
\item Dato $ \lambda \in \mathbb{R} $ si consideri $ u' = \lambda u $ in $ \mathbb{R} $. Tale equazione differenziale ha dimensione 1, ordine 1, \`e autonomo, lineare e omogeneo. Le soluzioni assumono la seguente forma:

\[ u(t) = C \exp(\lambda t) \]

con $ C \in \mathbb{R} $.

\begin{itemize}
\item Se $ \lambda > 0 $ si parla di crescita esponenziale ed \`e facilmente calcolabile con il metodo di Eulero esplicito;
\item Se $ \lambda < 0 $ si parla di decrescita esponenziale e si riscontrano problemi nel calcolo con il metodo di Eulero esplicito.
\end{itemize}

\item Un modello di crescita pi\`u flessibile \`e l'equazione di Verhulst

\[ u' = \lambda u \left( 1 - \frac{u}{k} \right) \]

che ha dimensione 1, ordine 1, \`e autonoma ma non \`e lineare. La soluzione generale \`e 

\[ u(t) = \frac{K C \exp (\lambda t)}{K + C (\exp (\lambda t) - 1)} \]

\item Dato un campo vettoriale $ f: \mathbb{R}^{3} \to \mathbb{R}^{3} $ la seconda legge di Newton pu\`o assumere la seguente forma in $ \mathbb{R} $:

\[ u'' = f(u) \]

che ha dimensione 3, ordine 2, \`e autonomo e in generale non \`e lineare. Il sottocaso lineare $ f(z) = - kz $, con $ z \in \mathbb{R}^{3} $, $ k \in \mathbb{R}^{d \times d} $ si dice oscillatore armonico;

\item Si consideri l'oscillatore armonico in una dimensione e con $ k  = 1 $:

\[ u'' = - u \]

Introducendo la nuova variabile $ v = u' $ si pu\`o riscrivere l'equazione con il seguente sistema

\[
\begin{cases}
u' = v \\
v' = -u
\end{cases} \iff \begin{pmatrix}
	u \\
	v \\
\end{pmatrix} ' = \begin{pmatrix}
	 0 & 1 \\
	-1 & 0 \\
\end{pmatrix} \begin{pmatrix}
	u \\
	v \\
\end{pmatrix}
\]

e con $ z = u + iv \in \mathbb{C} $ il problema diventa

\[ z' = -i z \]

poich\'e $ -i(u + iv) = -i u + v $. Questo corrisponde all'esempio $ 1. $ in $ \mathbb{C} $ con $ \lambda = -i $.
\end{enumerate}

\section{Problemi ai valori iniziali}
Le applicazioni e le soluzioni generali degli esempi nel paragrafo precedente suggeriscono di porre ulteriori condizioni per individuare una soluzione di un'equazione differenziale ordinaria.

\subsection{Problema ai valori iniziali}	\label{section:3.1}
Siano $ d, k \in \mathbb{N} $, $ \Omega \subseteq \mathbb{R} \times \mathbb{R}^{kd} $ dominio aperto e connesso. Sia $ f: \Omega \to \mathbb{R}^{d} $, $ (t_{0}, v_{0}, \dotsc, v_{k-1}) \in \Omega $, $ t_{0} < T $ e $ I = [t_{0}, T] $.

Una funzione $ u: I \to \mathbb{R}^{d} $ si dice soluzione di $ u^{(k)} = f(\cdot, u^{(0)}, \dotsc, u^{(k-1)}) $ con $ u^{(i)} (t_{0}) = v_{i} $ con $ i = 0, \dotsc, k - 1 $ se:
\begin{enumerate}
\item $ u $ \`e derivabile con continuit\`a $ k $ volte in $ I $ e $ \forall\ t \in I, \left( t, u^{(0)}(t), \dotsc, u^{(k-1)}(t) \right) \in \Omega $;
\item $ u^{(i)} (t_{0}) = v_{i} $ per $ i = 0, \dotsc, k - 1 $;
\item $ \forall\ t \in I, u^{(k)}(t) = f \left( t, u(t), \dotsc, u^{(k-1)}(t) \right) $.
\end{enumerate}

Introducendo nuove variabili, cio\`e aumentando $ d $, ci si pu\`o sempre  ridursi al caso $ k = 1 $. Da ora in poi si considerer\`a $ k = 1 $.

\subsection{Un esempio di non-unicit\`a}
Si consideri in $ [0, +\infty) $

\[ \begin{cases}
u' = 3 u^{\frac{2}{3}} \\
u(0) = 0
\end{cases}
\]

cio\`e $ \Omega = \mathbb{R} \times \mathbb{R}^{+}_{0} $, $ t_{0} = 0 $, $ v = 0 $, $ f(z) = 3 z^{\frac{2}{3}} $. Si osserva che
\begin{itemize}
\item $ u_{1}(t) \equiv 0 $
\item $ u_{2}(t) = t^{3} $
\end{itemize}
sono soluzioni del problema considerato. Si noti inoltre che

\[ \lim\limits_{z \to 0^{+}} f'(z) = \lim\limits_{z \to 0^{+}} 2 z^{-\frac{1}{3}} = \infty \]

\subsection{Un criterio di unicit\`a (per $ k = 1 $)}
Nelle ipotesi di \refsec{3.1} si supponga che $ k = 1 $. Se $ [f(t, z_{1}) - f(t, z_{2})] \cdot [z_{1} - z_{2}] \le l \vert z_{1} - z_{2} \vert^{2}, \forall\ (t, z_{1}), (t, z_{2}) \in \Omega $, dove
\begin{itemize}
\item $ \cdot $ \`e il prodotto scalare in $ \mathbb{R}^{d} $
\item $ l \in \mathbb{R} $
\end{itemize}

allora due soluzioni $ u_{1}, u_{2}: I \to \mathbb{R} $ di $ (\ref{eq:PVI}) $ coincidono in $ \mathcal{C}(I, \mathbb{R}^{d}) $.

\begin{proof}
$ \forall\ t \in I $ si ha

\begin{dmath*}
{ \frac{\mathrm{d}}{\mathrm{d}t} \left[ \frac{1}{2} \vert u_{1}(t) - u_{2}(t) \vert^{2} \right] } = { \left( u_{1}(t) - u_{2}(t) \right) \cdot \left( u_{1}' (t) - u_{2}' (t) \right) } = \\ { [ f \left( t, u_{1}(t) \right) - f \left( t, u_{2}(t) \right) ] \cdot [u_{1}(t) - u_{2}(t)] } \le { l \vert u_{1}(t) - u_{2} (t) \vert^{2} }
\end{dmath*}

Quindi

\[ d(t) \defeq \frac{1}{2} e^{-2lt} \vert u_{1}(t) - u_{2}(t) \vert^{2} \]

soddisfa

\[ d'(t) \le -l e^{-2lt} \vert u_{1}(t) - u_{2}(t) \vert^{2} + e^{-2lt} l \vert u_{1}(t) - u_{2}(t) \vert^{2} = 0 \]

da cui

\[ d(s) = \underbrace{d(0)}_{= 0} + \int\limits_{0}^{s} \underbrace{d'(t)}_{\le 0} \, \mathrm{d}t \]

e quindi, in $ I $

\[ d(t) \equiv 0 \implies u_{1} \equiv u_{2}  \]
\end{proof}

\section{Metodi numerici e condizionamento}
\subsection{Metodi numerici}

Un metodo numerico \`e una "mappa" del tipo

\begin{center}
(problema continuo, parametro) $ \mapsto $ problema discreto
\end{center}

Ad esempio in \refsec{1} abbiamo associato al problema continuo $ \ref{eq:PVI} $ e al parametro $ N \in \mathbb{N} $ il problema discreto $ (\ref{eq:EE}) $ con $ t_{n} = t_{0} + n \tau $ e $ \tau = \frac{T - t_{0}}{N} $. Si noti che i $ t_{i} $ sono tutti equidistanti. Se non lo fossero, come in metodi che verranno affrontati successivamente, al posto di un parametro si dovrebbe inserire un vettore di punti che formano la griglia dei tempi. Anche questa soluzione non \`e generale poich\'e alcuni metodi prevedono un ordine preciso di uso dei tempi $ t_{i} $. Per ora saranno considererati solo metodi con griglia equidistante.

I metodi "numerici" sono un modello dei metodi "computazionali".

\subsection{Convergenza}
Per valutare la bont\`a  di un metodo numerico \`e interessante bilanciare costo e qualit\`a: nel caso di \refsec{1}, ad esempio, sarebbe il bilanciamento di $ N $, dato che il numero dei passi \`e uguale al numero di valutazioni della $ f $ e quindi \`e approssimabile al costo computazionale, oppure  $ \max\limits_{n = 0, \dotsc, N} \vert u(t_{n})  - U_{n} \vert $. In particolare ci interessano le stime del tipo $ \max\limits_{n = 0, \dotsc, N} \vert u(t_{n})  - U_{n} \vert \le C N^{-p} $, con $ p > 0 $, che qualifica anche la velocit\`a di convergenza.

\subsection{Buona posizione e buon posizionamento}
I problemi continui e discreti dovrebbero essere ben posti, cio\`e, secondo Hadamard:
\begin{enumerate}
\item deve esistere almeno una soluzione;
\item deve esistere al pi\`u una soluzione;
\item la soluzione deve dipendere in modo continuo dai dati.
\end{enumerate}

Nel caso di $ (\ref{eq:PVI}) $ i dati sono $ f $ e $ v $. Inoltre, il problema discreto che viene "risolto" sul computer con aritmetica finita dovrebbe essere in particolare ben condizionato, cio\`e:
\begin{enumerate}
\item[4.] piccole perturbazioni nei dati producono piccole perturbazioni nella soluzione.
\end{enumerate}

Poich\'e il problema discreto discende dal problema continuo e si spera che lo "diventi" per $ N \to +\infty $, anche il problema continuo dovrebbe essere ben condizionato. Si noti che il punto 2 pu\`o essere riscritto nel seguente modo:
\begin{enumerate}
\item[2b.] nessuna perturbazione nei dati, quindi nessuna perturbazione nella soluzione.  
\end{enumerate}

In altre parole, prima di comprendere il punto 3 bisogna comprendere il punto 2.

\section{Buon condizionamento grazie alla CLU}

\subsection{Stabilit\`a}
Siano $ t_{0}, T \in \mathbb{R} $ come sempre con $ t_{0} < T $, $ f: [t_{0}, T] \times \mathbb{R}^{d} \to \mathbb{R}^{d} : \forall\ t \in [t_{0}, T], z_{1}, z_{2} \in \mathbb{R}^{d} $ si ha:

\[
[ f(t, z_{1}) - f(t, z_{2}) ] \cdot [z_{1} - z_{2}] \leq l \cdot \Vert z_{1} - z_{2} \Vert^{2}
\]

per qualche $ l \in \mathbb{R} $. Siano poi $ v \in \mathbb{R}^{d} $ e $ u, \tilde{u} \in \mathcal{C}^{1}([t_{0}, T], \mathbb{R}^{d}) $ soluzioni rispettivamente delle due equazioni differenziali:

\[
\begin{cases}
u' = f(\cdot, u) \\
u(t_{0}) = v
\end{cases}
\]

\[\begin{cases}
\tilde{u}' = f(\cdot, u) + \delta \\
\tilde{u}(t_{0}) = v + \rho = \tilde{v}
\end{cases}
\]

nell'intervallo $ [t_{0}, T] $ dove $ \delta: [t_{0}, T] \to \mathbb{R}^{d} $ e $ \rho \in \mathbb{R}^{d} $. Allora:
 
\[
\vert u(t) - \tilde{u}(t) \vert \leq e^{l(t - t_{0})} \vert \rho \vert + \int\limits_{t_{0}}^{t} e^{l(t - s)} \vert \delta(s) \vert \, \mathrm{d}s \]

Se $ l < 0 $ si ha una decrescita esponenziale, se $ l > 0 $ una crescita. Si potrebbe raffinare $ l $ e farla dipendere da $ t $.

\begin{proof}
La presenza di $ \delta $ suggerisce di considerare $ \Vert u - \tilde{u} \Vert $ al posto di $ \Vert u -  \tilde{u} \Vert^{2} $. Per evitare problemi di derivabilit\`a in $ 0 $, si consideri dapprima $ \sqrt{\varepsilon^{2} + \Vert u - \tilde{u} \Vert^{2}} $ e poi il limite $ \varepsilon \to 0 $.

Seguendo 1.3.3 si osserva:	% TODO: cosa sarebbe 1.3.3?

\begin{dmath*}
{ \frac{\mathrm{d}}{\mathrm{d} t} [\sqrt{\varepsilon^{2} + \Vert u - \tilde{u} \Vert^{2}}] } = { \frac{1}{2} \frac{2 \cdot (u - \tilde{u}) \cdot (u' - \tilde{u}')}{\sqrt{\varepsilon^{2} + \Vert u - \tilde{u}\Vert^{2}}} } = { \frac{(u - \tilde{u}) \cdot (f(\cdot, u) - f(\cdot, \tilde{u}) - \delta)}{\sqrt{\varepsilon^{2} + \Vert u - \tilde{u} \Vert^{2}}} } \leq \\ { l \cdot \frac{\Vert u - \tilde{u} \Vert^{2}}{\sqrt{\varepsilon^{2} + \Vert u - \tilde{u} \Vert^{2}}} + \vert \delta \vert \frac{\Vert u - \tilde{u} \Vert^{2}}{\underbrace{\sqrt{\varepsilon^{2} + \Vert u - \tilde{u} \Vert^{2}}}_{\leq 1}} } \leq { l \cdot \frac{\Vert u - \tilde{u} \Vert^{2}}{\sqrt{\varepsilon^{2} + \Vert u - \tilde{u} \Vert^{2}}} + \vert \delta \vert }
\end{dmath*}
 
Come prima si consideri la funzione:

\[ d_{\varepsilon}(t) \defeq e^{-l(t - t_{0})} \sqrt{\varepsilon^{2} + \Vert u - \tilde{u} \Vert^{2}} \]

e si osserva che: 
 
\begin{dmath*}
{ d_{\varepsilon}'(t) } \leq { - l e^{-l(t - t_{0})} \sqrt{\varepsilon^{2} + \Vert u - \tilde{u} \Vert^{2}} + e^{-l(t - t_{0})} \left[ l \cdot \frac{\Vert u - \tilde{u}\Vert^{2}}{\sqrt{\varepsilon^{2} + \Vert u - \tilde{u} \Vert^{2}}} + \vert \delta \vert \right] } = { e^{-l(t - t_{0})} \left[ \vert \delta \vert + l \frac{-\varepsilon^{2} - [u - \tilde{u}] + [u - \tilde{u}]^{2}}{\sqrt{\varepsilon^{2} + \vert u - \tilde{u} \vert^{2}}} \right] } \leq { e^{-l(t - t_{0})} \left[ \vert \delta \vert + \vert l \vert \cdot \varepsilon \frac{\varepsilon}{\sqrt{\varepsilon^{2} + \vert u - \tilde{u} \vert^{2}}} \right] } \leq { e^{-l(t - t_{0})} [ \vert \delta \vert + \varepsilon \vert l \vert ] }
\end{dmath*}

Di conseguenza:

\[
d_{\varepsilon} (t) = d_{\varepsilon}(t_{0}) + \int\limits_{t_{0}}^{t} d_{\varepsilon}'(s)\, \mathrm{d}s = d_\varepsilon(t_{0}) + \int\limits_{t_{0}}^{t} e^{-l(s - t_{0})} \vert \delta(s) \vert\, \mathrm{d}s + \varepsilon \cdot \vert l \vert \cdot \int\limits_{t_{0}}^{t} e^{-l(s - t_{0})}\,\mathrm{d}s
\]
 
E considerando $ \varepsilon \to 0 $ si ottiene:

\[ d_{0}(t) \leq d_{0}(t_{0})+ \int\limits_{t_{0}}^{t} e^{-l(s - t_{0})} \cdot \vert \delta(s) \vert\, \mathrm{d}s + 0 \] 

ovvero che:

\[ e^{-l(t - t_{0})} \cdot \Vert u - \tilde{u} \Vert \leq \vert \rho \vert + \int\limits_{t_{0}}^{t} e^{-l(s - t_{0})} \cdot \vert \delta(s) \vert\, \mathrm{d}s \]

da cui la tesi moltiplicando per $ e^{l(t - t_{0})} $.
\end{proof}

\section{Residuo e consistenza}
\subsection{Poligono di Eulero}

La soluzione discreta del metodo di Eulero esplicito fornisce valori solo sulla griglia generale $ t_{n} = t_{n-1} + \tau_{n} $ con $ n = 0, 1, \dotsc, N - 1 $ e $ \tau = 0, \dotsc, T_{N - 1} > 0 $ tali che $ \sum\limits_{k = 0}^{N - 1} \tau_{n} = T - t_{0} $. Quindi non pu\`o essere vista come perturbazione di $ u $.

Per rimediare si passa al poligono di Eulero: una funzione $ U: [t_{0}, T] \to \mathbb{R}^{d} $ definita da

\begin{dmath*}
U(t) = \frac{t - t_{n - 1}}{\tau_{n}} U_n + \frac{t_{n} - t}{\tau_{n}} U_{n - 1} = U_{n - 1} + (t - t_{n - 1}) \frac{U_{n} - U_{n-1}}{\tau_{n}} = U_{n - 1} + (t - t_{n - 1}) f(t_{n - 1}, U_{n - 1})
\end{dmath*}

\begin{center}
\begin{figure}[H]
\begin{tikzpicture}
      \draw[->] (-1, 0) -- (7,0) node[right] {$ t $};
      \draw[->] (0, -1) -- (0, 3.5) node[above] {$ U(t) $};
      \draw (0, 0.8) -- (2, 2) -- (4, 1.2) -- (6, 2.8) -- (6.5, 2.6);

      \node [below left] at (0, 0) {$ t_{0} $};
      \draw[dashed] (2, 2) -- (2, 0) node[below] {$ t_{1} $};
      \draw[dashed] (4, 1.2) -- (4, 0) node[below] {$ t_{2} $};
      \draw[dashed] (6, 2.8) -- (6, 0) node[below] {$ t_{3} $};
      
      \draw [fill] (2,2) circle (1pt) node[above] {$ f(t_{0}, U_{0}) $};
      \draw [fill] (4,1.2) circle (1pt) node[below] {$ f(t_{1}, U_{1}) $};
      \draw [fill] (6,2.8) circle (1pt) node[above] {$ f(t_{2}, U_{2}) $};
\end{tikzpicture}

\caption{Esempio di poligono di Eulero}
\end{figure}
\end{center}

\subsection{Residuo del poligono di Eulero}
Dato il poligono di Eulero, si definisce residuo la quantit\`a:

\[ R(t) \defeq u'(t) - f(t, U(t)) \]

per $ t \in (t_{n - 1}, t_{n}) $ e si osserva che $ u'(t) = f(t, U(t)) + R(t) $, di conseguenza nelle ipotesi del teorema precedente si ha:

\[ \Vert u(t) - U(t) \Vert \leq \int\limits_{t_{0}}^{t} e^{l(t - s)} \vert R(s) \vert \, \mathrm{d}s \] 

dove:

\[
\int\limits_{t_{n}}^{t_{n + 1}} e^{l(t - s)} \vert R(s) \vert \, \mathrm{d}s = \int\limits_{t_{n}}^{t_{n + 1}} e^{l(t - s)} [f(t_{n}, U_{n}) - f(s, U(s))] \, \mathrm{d}s
\]

\`e calcolabile (modulo integrazione numerica) pu\`o essere associato al passo $ n $.	% TODO: frase non chiara

\subsection{Consistenza del passo}
Una controparte del residuo pu\`o essere:

\[
\frac{U(t_{n - 1}) - u(t_{n})}{\tau_{n}} - f(t_{n}, U(t_{n})) = \frac{\varepsilon(t_{n}, U(t_{n}),\tau_{n})}{\tau_{n}} \eqdef \frac{\varepsilon_{n}}{\tau_{n}}
\]

Infatti esso misura per quanto la soluzione esatta non soddisfa la soluzione discreta mentre il residuo misura per quanto l'approssimazione $ U $ non soddisfa l'equazione continua supponendo che il problema discreto sia ben condizionato oppure vale una controparte di $ 1.5.1 $, ci si pu\`o aspettare una stima dell'errore in termini di $ \frac{\varepsilon_{n}}{\tau_{n}} $, con $ n = 0, \dotsc, N - 1$. Si noti che grazie a $ u' = f(t, u) $ si ha:	% TODO: cosa sarebbe 1.5.1?

\[ \frac{\varepsilon(t, U(t), \tau)}{\tau} = \frac{U(t + \tau) - U(t)}{\tau_{n}} - f(t, U(t)) \to 0 \]

per $ \tau \to 0 $ poich\'e u \`e derivabile in $ \tau $.

\chapter{Consistenza e regolarit\`a}
\setcounter{section}{6}
\section{Preliminari}
\subsection{Evoluzione}	\label{section:7.1}
Sia $ \Omega \subseteq \mathbb{R} \times \mathbb{R}^{d} $, $ f: \Omega \to \mathbb{R}^{d} $ tale che $ \forall\ (t_{0}, v) \in \Omega $ il problema

\begin{equation}	\label{eq:probevol}
\begin{cases}
u' = f(\cdot, u) \\
u(t_{0}) = v
\end{cases}
\end{equation}

ha un'unica soluzione massimale $ u(t_{0}, v) : [t_{0}, T(t_{0}, v)] \to \mathbb{R}^{d} $ derivabile in $ t_{0} $. Qui massimale significa che se $ \tilde{u} : [t_{0}, \tilde{T}] \to \mathbb{R}^{d} $ \`e un'altra soluzione allora $ \tilde{T} < T(t_{0}, v) $ e $ \tilde{u} = u $ su $ [t_{0}, \tilde{T}) $

Si pone quindi, $ \forall\ t \in [t_{0}, T(t_{0}, v)] $

\[ \varphi(t, t_{0}) v = u_{(t_{0}, v)} (t) \]

chiamata evoluzione di $ f $.

\begin{oss}
\noindent
\begin{enumerate}
\item $ \varphi(t_{0}, t_{0}) v = v $;
\item Se $ t_{0} \le t_{1} \le t_{2} \le t_{3} < T(t_{0}, v) $ allora $ \varphi(t_{3}, t_{2}) \varphi(t_{2}, t_{1}) v = \varphi(t_{3}, t_{1}) v $;
\item $ \lim\limits_{\tau \to 0^{+}} \frac{\mathrm{d}}{\mathrm{d} \tau} \varphi (t + \tau, t)v = \lim\limits_{\tau \to 0^{+}} \frac{\varphi(t + \tau, t)v - \varphi(t, t)v}{\tau} = f(t, v) $
\end{enumerate}
\end{oss}

\subsection{Metodi a un passo}

Siano $ \Omega, f $ e $ \varphi $ come nel capitolo precedente. Un metodo ad un passo associa a $ f $ una funzione incremento $ F = F(t, z, \tau), \forall\ (t, z) \in \Omega, \tau \in [0, \tau(t, z)] $ con $ \tau(t, z) > 0 $. Posto

\[ \Phi (t_{1}, t_{2}) v = v + (t_{2} - t_{1}) F(t_{1}, v, t_{2} - t_{1}) \]

una soluzione approssimata di $ (\ref{eq:probevol}) $ in \refsec{7.1} sulla griglia

\[ t_{0} < t_{1} < \dotsb < t_{N} \]

\`e data da 

\[
\begin{cases}
U_{n+1} = \Phi(t_{n + 1}, t_{n}) U_{n} \\
U_{0} = v
\end{cases}
\]

\begin{oss}
\noindent
\begin{enumerate}
\item $ \Phi(t_{n+1}, t_{n}) v $ vuole approssimare $ \varphi(t_{n + 1}, t_{n}) $
\item Per il calcolo di $ U_{N} $ non \`e necessario memorizzare $ U_{0}, \dotsc, U_{N - 2} $
\item $ \Phi (t_{0}, t_{0}) v = v $ ma in generale non si ha, per $ 0 \le n \le k \le l \le N $

\[ \Phi(t_{l}, t_{k}) \Phi(t_{k}, t_{n}) v  = \Phi(t_{l}, t_{n}) v \]
\end{enumerate}
\end{oss}

\begin{es}
Per il metodo di Eulero esplicito si ha, con $ (t, z) \in \Omega, T > 0 $

\[ F(t, z, \tau) = f(t, z) \]
\end{es}

\subsection{Teorema di Taylor}

Sia $ I $ intervallo, $ r \in \mathbb{N} $ e $ u \in \mathcal{C}^{r} (I, \mathbb{R}^{d}) = \{ w : I \to \mathbb{R}^{d} : w^{(0)}, \dotsc, w^{(r)} \text{ esistono e sono continue in } I \} $. Allora

\[ \underbrace{u(s)}_{\in I} = \sum\limits_{k = 0}^{r - 1} \frac{u^{(k)}(t)}{k!} (s - t)^{k} + \frac{1}{(k - 1)!} \int\limits_{t}^{s} u^{(r)} (\xi) (s - t)^{r} \, \mathrm{d}\xi \]

\begin{proof}
Analisi
\end{proof}

\subsection{Simboli di Landau}

Sia $ f: [0, \tau^{\ast}] \to \mathbb{R}^{d} $ e $ b: [0, \tau^{\ast}] \to \mathbb{R}^{\ast} = \mathbb{R} \setminus \{ 0 \} $.

\begin{itemize}
\item $ f = O (b) $ per $ \tau \to 0 $ se $ \exists\ C \ge 0, \tau_{0} \in (0, \tau^{\ast}) : \vert f(\tau) \vert \le C b(\tau) $
\item $ f = o(b) $ per $ \tau \to 0 $ se $ \lim\limits_{\tau \to 0^{+}} \frac{\vert f(\tau) \vert}{b(\tau)} = 0 $
\end{itemize}

\begin{es}
\noindent
\begin{itemize}
\item $ u $ continua in $ t \implies u(t + \tau) = u(t) + o(1) $ per $ \tau \to 0 $;
\item $ u $ lipschitziana $ \implies u(t + \tau) = u(t) + O(\tau) $;
\item $ u $ \`e derivabile in $ t \implies u(t + \tau) = u(t) + u'(t) \tau + o(\tau) $
\end{itemize}
\end{es}

\section{Consistenza di metodi a un passo}
\subsection{Definizione di consistenza}	\label{section:8.1}

Un metodo ad un passo con $ \Phi $ e $ F $ si dice consistente per $ u' = f(\cdot, u) $ se una delle seguenti condizioni equivalenti \`e soddisfatta:

\begin{enumerate}
\item $ \forall\ (t, z) \in \Omega, \lim\limits_{\tau \to 0^{+}} \frac{\mathrm{d}}{\mathrm{d} \tau} \Phi(t + \tau, t)z = f(t, z) $
\item $ \forall\ (t, z) \in \Omega, \lim\limits_{\tau \to 0} F(t, z, \tau) = f(t, z) $
\item $ \forall\ (t, z) \in \Omega, \varepsilon(t, z, \tau) \defeq \varphi(t + \tau, t)z - \Phi(t + \tau, t)z = o(\tau) $ per $ \tau \to 0 $
\end{enumerate}

Si osserva che $ \varepsilon(t, z, \tau) \defeq \varphi(t + \tau, t)z - [z + \tau F(t, z, \tau)] $ misura per quanto la soluzione esatta non \`e una soluzione del metodo.

\begin{proof}
\noindent
\begin{itemize}
\item[$ 1. \implies 2. $] $ \lim\limits_{\tau \to 0} F(t, z, \tau) = \lim\limits_{\tau \to 0} \frac{\Phi (t + \tau, t)z - z}{\tau} = \lim\limits_{\tau \to 0^{+}} \Phi(t + \tau, t)z \stackrel{1.}{=} f(t, z) $
\item[$ 2. \implies 3. $] $ \varepsilon(t, \tau, z) = \varphi(t + \tau, t) z - \Phi(t + \tau, t) z = z + \int\limits_{t}^{t + \tau} f(s, \varphi(t + s)) \, \mathrm{d}s - {[z + \tau F(t, z, \tau)]} = \int\limits_{t}^{t + \tau} f(s, \varphi(t + s)) - F(t, z, \tau) \, \mathrm{d}s = {\underbrace{\int\limits_{t}^{t + \tau} \underbrace{f(s + t, \underbrace{\varphi(t + s, t)z}_{= z + o(1) \text{ per } \tau \to 0}) - f(t, z)}_{= o(1)} \, \mathrm{d}s}_{= o(\tau)}} + {\underbrace{\int\limits_{t}^{t + \tau} \underbrace{f(t, z) - F(t, z, \tau)}_{= o(1) \text{ per } \tau \to 0} \, \mathrm{d}s}_{= o(\tau)}} $
\item[$ 3. \implies 1. $] $ \lim\limits_{\tau \to 0} \frac{\mathrm{d}}{\mathrm{d} \tau} \Phi(t + \tau, t)z = \lim\limits_{\tau \to 0} \frac{\Phi(t + \tau, t)z - z}{\tau} = \lim\limits_{\tau \to 0} \frac{\varphi(t + \tau, t)z - z}{\tau} - \frac{\overbrace{\varepsilon(t , z, \tau)}^{o(\tau)}}{\tau} = f(t, z) + 0 $
\end{itemize}
\end{proof}

\subsection{Consistenza del metodo di Eulero esplicito}	\label{section:8.2}
Dato $ (t, z) \in \Omega $, si scrive 

\[ u(t + \tau) = \Phi(t + \tau, t) z \]

Si ha, per $ \tau \to 0 $, che $ \varepsilon_{EE} (t, z) = u(t + \tau) - [u(t) + \tau f(t, u(t))] = u(t + \tau) - u(t) - \tau u'(t) = \int\limits_{t}^{t + \tau} u'(s) \, \mathrm{d}s - \tau u'(t) = \underbrace{\int\limits_{t}^{t + \tau} \underbrace{u'(s) - u'(t)}_{= o(1) \text{ se $ u $ continua in } t} \, \mathrm{d}s}_{O(\vert s - t \vert) = O(\tau^{2})} = o(\tau) $

\section{Un metodo di ordine superiore}
\subsection{Un ordine di pi\`u per $ \varepsilon $. L'errore di consistenza}
In \refsec{8.2} si \`e osservato che l'errore di consistenza di Eulero esplicito \`e di $ O(\tau^{2}) $ per $ \tau \to  0$ se la soluzione di $ u'= f(\cdot u) $ \`e due volte derivabile con continuit\`a . Si cerca di derivare un metodo per cui l'errore di consistenza pu\`o soddisfare $ O(\tau^{3}) $ per $ \tau \to 0 $. A questo scopo si osserva che

$ u(t + h) - u(t - h) = u(t) + h u'(t) + \frac{1}{2} h^{2} u''(t) + \frac{1}{6} h^{3} u^{(3)} (t^{+}) - [u(t) - h u'(t) + \frac{1}{2} h^{2} u''(t) - \frac{1}{6} h^{3} u^{(3)} (t^{-})] = 2h u'(t) + O(t^{3}) $ 

ovvero

\begin{equation}
u'(t) = \frac{u(t + h) - u(t - h)}{2h} + O(h^{3})
\end{equation} 

Sia $ t_{0} < t_{1} < \dotsb < t_{N} = T $ uan griglia e $ \tau_{n} = t_{n + 1} - t_{n} $, con $ n = 0, \dotsc, N - 1 $. Ponendo $ \tau_{n} = \frac{h}{2} $ conduce a $ \frac{u(t_{n + 1}) - u(t_{n})}{\tau_{n}} = u' \left( t_{n} + \frac{\tau_{n}}{2} \right) + O(\tau_{n}^{2}) = f(t_{n} + \frac{\tau_{n}}{2}, u \left( t_{n} + \frac{\tau_{n}}{2} \right)  + O(\tau_{n}^{2}) $. Il problema \`e che $ t_{n} + \frac{\tau_{n}}{2} $ non \`e un punto della griglia, quindi approssimando $ u \left( t_{n} + \frac{\tau_{n}}{2} \right) $ con il metodo di Eulero esplicito con passo $ \frac{\tau_{n}}{2} $ si ottiene 

\[ u \left( t_{n} + \frac{\tau_{n}}{2} \right) = u(t_{n}) + \frac{\tau_{n}}{2} f(t_{n}, u(t_{n})) + O(\tau_{n}^{2}) \]

e, supponendo che $ f = f(t, z) $ \`e Lipschitz rispetto a $ z $, si ottiene

\[ f \left( t_{n} + \frac{\tau_{n}}{2}, u \left(t_{n} + \frac{\tau_{n}}{2} \right) \right) = f(t_{n} + \frac{\tau_{n}}{2}, u(t_{n} + \frac{\tau_{n}}{2} f(t_{n}, u(t_{n}) ) + O(\tau_{n}^{2})  \]

Riassumendo, si ha sotto le ipotesi fatte, per $ \tau \to 0 $

\[ \frac{u(t_{n + 1}) - u(t_{n})}{2 \tau_{n}} = f \left( t_{n} + \frac{\tau_{n}}{2}, u(t_{n}) + \frac{\tau_{n}}{2} f(t_{n}, u(t_{n}) \right) + O(\tau_{n}^{2} \]

Questo suggerisce il cosiddetto metodo di Eulero modificato

\[
\begin{cases}
U_{0} = v \\
U_{n + 1} = U_{n} + \tau f \left( t_{n} + \frac{\tau_{n}}{2}, U_{n} + \frac{\tau_{n}}{2} f(t_{n}, U_{n}) \right)	 & n = 0, \dotsc, N - 1
\end{cases}
\]

Si noti che qui la funzione $ f $ viene valutato due volte per passo. 

\subsection{Ordine sperimentale dell'errore di Eulero modificato}
In un problema dove $ f $ \`e Lipschitz rispetto a  $ z $ e $ u $ tre volte derivabile con continuit\`a si osserva effettivamente che nel tempo finale $ T $

\[ \vert U_{n} - u(T) \vert \approx \tau^{2} = \frac{1}{N^{2}} \]

\begin{center}
\begin{tabular}{c|c|c}
	Metodo & Costo & Errore \\
\hline
	E. E. & $ N $ & $ \approx \frac{1}{N} $ \\
\hline
	E. M. & $ 2N $ & $ \approx \frac{1}{4N^{2}} $ \\
\end{tabular}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Velocit\`a di convergenza e dipendenza dalla regolarit\`a}
\subsection{Eulero esplicito vs. Eulero modificato}

Nella seguente tabella viene mostrato il costo in termini di valutazion edella $ f $ dei metodi di Eulero esplicito ed Eulero modificato per raggiungere un dato livello di errore relativo (\refsec{9.3})	% TODO: NON ESISTE 9.3!

\begin{tabular}{c|c|c|c|c}
	Tolleranza & $ 10\% $ & $ 1\% $ & $ 0.1\% $ & $ 0.01\% $ \\
\hline
	E.E. & 8 & 64 & 512 & 8192 \\
\hline
	E.M. & 2 & 8 & 32 & 128 \\
\hline
	Raddoppio & 4 & 8 & 16 & 64 \\
\end{tabular}

Questo viene illustrato anche nel bilancio qualit\`a-costo in scala $ \log-\log $

\begin{center}
\begin{figure}[H]
\begin{tikzpicture}
	\draw[->] (-1, 0) -- (5, 0) node[right] {$ \log N $};
	\draw[->] (0, -5) -- (0, 1) node[above] {$ \log \mathop{err} $};
	\filldraw (1, 0) circle (1pt) node[above] {$ 10^{1} $};
	\filldraw (2, 0) circle (1pt) node[above] {$ 10^{2} $};
	\filldraw (3, 0) circle (1pt) node[above] {$ 10^{3} $};
	\filldraw (4, 0) circle (1pt) node[above] {$ 10^{4} $};
	\filldraw (0, -1) circle (1pt) node[left] {$ 10^{-1} $};
	\filldraw (0, -2) circle (1pt) node[left] {$ 10^{-2} $};
	\filldraw (0, -3) circle (1pt) node[left] {$ 10^{-3} $};
	\filldraw (0, -4) circle (1pt) node[left] {$ 10^{-4} $};
	\draw (1, 0) -- (4.5, -3.5);
	\draw (1, 0) -- (3.25, -4.5);
\end{tikzpicture}

\caption{$ \mathop{err} \approx C N^{-p} \iff \log \mathop{err} \approx \log C - p \log N $}
\end{figure}
\end{center}

\subsection{Impatto della regolarit\`a}
Si consideri il problema

\[
\begin{cases}
u' = t^{p} u & \text{ in } (0, 1) \\
u(1) = \exp \left( \frac{1}{1 + p} \right) 
\end{cases}
\]

con $ p > -1 $. La soluzione \`e $ u(t) = \exp \left( \frac{t^{p + 1}}{p + 1} \right) $ per $ t \ge 0 $. Posto $ f(t, z) = t^{p} z $, con $ z \in \mathbb{R} $ e $ t > 0 $ si ha il seguente grafico:

\begin{center}
\begin{figure}[H]
\begin{tikzpicture}
	\draw[->] (-1, 0) -- (2, 0) node[right] {$ z $};
	\draw[->] (0, -1) -- (0, 3) node[right] {$ f(2, z) $};
	\filldraw (1, 0) circle (1pt) node[below] {$ 1 $};
	\filldraw (0, 0) circle (1pt) node[below left] {$ 0 $};

    \draw[domain=0:1, dashed, smooth] plot (\x, {2*\x^0.4});
    \draw[domain=0.05:1, smooth] plot (\x, {2*\x^(-0.1)});
    \draw[domain=0:1, dotted, smooth] plot (\x, {2*\x});
    \draw[domain=0:1, smooth] plot (\x, {2*\x^10});
\end{tikzpicture}

\caption{Grafici di $ f(2, z) $ con $ p = 1 $ (puntinato), $ p = 0.4 \in (0, 1) $ (tratteggiato), $ p = 10 \gg 1 $ (grafico inferiore) e $ p = -0.7 \in (-1, 0) $ (grafico superiore)}
\end{figure}
\end{center}

Si osserva numericamente che:
\begin{enumerate}
\item con l'aumentare di $ p \gg 1 $ l'ordine del metodo si osserva pi\`u tardi, cio\`e per $ N $ grandi;
\item per $ p \in (0, 1) $ il metodo di Eulero modificato mostra solo un ordine di convergenza di $ p + 1 < 2 $. Una "spiegazione" \`e data dalla barriera dell'errore di consistenza dell'ultimo passo $ \approx \tau^{3} \tau^{p - 2} = \tau^{p + 1} $;
\item per $ p \in (-1, 0) $ entrambi i metodi mostrano solo l'errore di convergenza $ 1 + p < 1 $. Una "spiegazione" \`e data da $ \tau^{2} \tau^{p - 1} = \tau^{p + 1} $.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

										MANCANO LE LEZIONI 11 E 12!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Metodi di Runge-Kutta}
\subsection{Definizione}
Un metodo di Runge-Kutta (RK) a $ s \in \mathbb{N} $ stadi \`e determinato da:

\begin{itemize}
\item $ A = (a_{ij})_{i, j = 1, \dotsc, s} \in \mathbb{R}^{s \times s} $
\item $ b = (b_{1}, \dotsc, b_{s})^{T} \in \mathbb{R}^{s} $
\item $ c = (c_{1}, \dotsc, c_{s})^{T} \in \mathbb{R}^{s} $ 
\end{itemize}

e associa a una funzione $ f: \Omega \subseteq \mathbb{R} \times \mathbb{R}^{d} \to \mathbb{R}^{d} $ la funzione

\[ F(t, z, \tau) = \sum\limits_{i = 1}^{s} b_{i} k_{i} \]

dove gli stadi $ k_{1}, \dotsc, k_{s} \in \mathbb{R}^{d} $ sono "la" soluzione del sistema non lineare

\begin{equation}	\label{eq:ki}
k_{i} = f \left( t + c_{i} \tau, z + \tau \sum\limits_{j = 1}^{s} a_{ij} k_{j} \right)
\end{equation}

con $ i = 1, \dotsc, s $. I parametri si rappresentano solitamente con il cosiddetto schema di Butcher

\begin{center}
\begin{tabular}{c|ccc}
                  &   &       & \\
$ \underline{c} $ &   & $ A $ & \\
				  &   &       & \\
\hline
				  &   & $ \underline{b}^{T} $ & \\
\end{tabular}
\end{center}

Il metodo si dice esplicito se $ a_{ij} = 0 $ per $ j \ge i $, ovvero $ A = \begin{pmatrix}
	     0 &      0 & \ldots &      0 \\
	  \ast & \ddots & \ddots & \vdots \\
	\vdots & \ddots & \ddots &      0 \\
	  \ast & \ldots &   \ast &      0 \\
\end{pmatrix} $. In questo caso, $ (\ref{eq:ki}) $ di riduce a:
\begin{itemize}
\item $ k_{1} = f(t + c_{1} \tau, z) $
\item $ k_{2} = f(t + c_{2} \tau, z + \tau a_{21} k_{1}) $
\item $ k_{s} = f \left( t + c_{s} \tau, z + \tau \sum\limits_{j = 1}^{s-1} a_{sj} k_{j} \right) $
\end{itemize}

\subsection{Esempi}
\begin{enumerate}
\item Eulero esplicito:
\[ F(t, z \tau) = f(t, z) \]

\begin{center}
\begin{tabular}{c|c}
$ 0 $ & $ 0 $ \\
\hline
	  & $ 1 $ \\
\end{tabular}
\end{center}
\item Eulero modificato: 
\[ F(t, z \tau) = f \left( t + \frac{\tau}{2}, z + \frac{\tau}{2} f(t, z) \right) \]

\begin{center}
\begin{tabular}{c|cc}
          $ 0 $ &           $ 0 $ & $ 0 $ \\
$ \frac{1}{2} $ & $ \frac{1}{2} $ & $ 0 $ \\
\hline
                &           $ 0 $ & $ 1 $ \\

\end{tabular}
\end{center}
\item Eulero implicito:
\[ z^{+} = z + \tau f(t + \tau, z^{+}) \iff \frac{z^{+} - z}{\tau} = \underbrace{f(t + \tau, z^{+})}_{\eqdef k_{1}} \iff k_{1} = f(t + \tau, z + \tau k_{1}) \]

\begin{center}
\begin{tabular}{c|c}
$ 1 $ & $ 1 $ \\
\hline
	  & $ 1 $ \\
\end{tabular}
\end{center}
\end{enumerate}

\subsection{Consistenza}
Un metodo Runge-Kutta definito da $ (A, \underline{b}, \underline{c}) $ \`e consistente $ \forall\ f $ continua se e solo se $ \sum\limits_{i = 1}^{s} b_{i} = 1 $.

\begin{proof}
Essendo un metodo a un passo si pu\`o usare \refsec{8.1} (2). Nel caso di $ \tau = 0 $, $ (\ref{eq:ki}) $ si riduce a

\[ k_{i} = f \left(t + c_{i} 0, z + 0 \sum\limits_{j = 1}^{s} a_{ij} k_{j} \right) = f(t, z) \]

$ \forall\ i = 1, \dotsc, s $ da cui $ F(t, z, 0) = \sum\limits_{i = 1}^{s} b_{i} k_{i} = \left( \sum\limits_{i = 1}^{s} b_{i} \right) f(t, z) $. Se il metodo \'e consistente allora $ F(t, z, 0) = f(t, z) $ e $ f(t, z) \ne 0 $ implica $ \sum\limits_{i = 1}^{s} b_{i} = 1 $. Viceversa, se $ \sum\limits_{i = 1}^{s} b_{i} = 1 $ e se $ k_{i} = k_{i} (t, z) $ sono continui in $ (t, z) $, allora vale \refsec{8.1} (2)  e il metodo definito da $ (A, \underline{b}, \underline{c}) $ \`e consistente.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

										MANCANO LE LEZIONI 14 E 15!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Passi adattivi - idea e potenziale}	\label{section:16}
\subsection{Passi da seguire}

Sia $ \Phi $ l'evoluzione di un metodo a un passo per

\[ u' = f(\cdot, u) \]

con $ f \in \mathcal{C}^{0} (\Omega, \mathbb{R}^{d}) $ e $ (t_{0}, \underline{v}) \in \Omega $. Si ponga $ u(t) = \varphi(t, t_{0}) v $ e

\[
\begin{cases}
U_{0} \defeq v \\
U_{n + 1} \defeq \Phi(t_{n + 1}, t_{n}) U_{n}
\end{cases}
\]

dove $ t_{n + 1} = t_{n} + \tau_{n} $ e  $ t_{N} = T $ e i $ \tau_{i} $, con $ i = 0, \dotsc, N - 1 $, sono da scegliere.

\begin{center}
\begin{figure}[H]
\begin{tikzpicture}
	\draw[->] (-4, 0) -- (4, 0) node[right] {$ t $};
	\filldraw (-3, 0) circle (1pt) node[above] {$ t_{0} $};
	\draw (-2.5, 0) node[below] {$ \tau_{0} $};
	\filldraw (-2, 0) circle (1pt) node[above] {$ t_{1} $};
	\draw (-1.75, 0) node[below] {$ \tau_{1} $};
	\filldraw (-1.5, 0) circle (1pt) node[above] {$ t_{2} $};
	\draw (-0.25, 0) node[below] {$ \ldots $};
	\filldraw (1, 0) circle (1pt) node[above] {$ t_{i} $};
	\draw (1.75, 0) node[below] {$ \ldots $};
	\filldraw (2, 0) circle (1pt) node[above] {$ t_{N-1} $};
	\draw (2.5, 0) node[below] {$ \tau_{N-1} $};
	\filldraw (3, 0) circle (1pt) node[above] {$ t_{N} = T $};
\end{tikzpicture}

\caption{Esempio di griglia adattiva}
\end{figure}
\end{center}

Ci interessa una scelta "ottima", cio\`e del tipo: fissato $ N $, si minimizzi $ {\vert u(T) - U_{N} \vert} $, $ {\max\limits_{n = 1, \dotsc, N} \vert u(t_{n}) - U_{n} \vert } $ oppure $ { \sup\limits_{t \in [t_{0}, T]} \vert u(t) - U_{t} \vert } $, con $ U(t) $ da definire. In alternativa si pu\`o considerare fissato $ \varepsilon > 0 $ la minimizzazione di $ N $ con $ { \vert u(T) - U_{N} \vert \le \varepsilon } $.

\subsection{Un problema di approssimazione del modello}
Sia $ u \in \mathcal{C}^{0} ([t_{0}, T]) $ e si consideri

\[ \inf\limits_{t_{1} < \dotsb < t_{N}} \Vert u - \overline{u} \Vert_{[t_{0}, T]} \]

con $ \Vert u - s \Vert_{[t_{0}, T]} \defeq \sup\limits_{t \in [t_{0}, T]} \Vert u(t) - s(t) \Vert $ e $ \overline{u}_{\big\vert [t_{n}, t_{n + 1})} = u(t_{n}) $

\begin{center}
\begin{figure}[H]
\begin{tikzpicture}
	\draw[->] (-1, 0) -- (5, 0) node[right] {$ t $};
	\draw[->] (0, -1) -- (0, 5) node[above] {$ u, \overline{u} $};
	\draw[dotted] (0, 0.4) -- (0, 0) node[below left] {$ t_{0} $};
	\draw[dotted] (0.5, 0.5) -- (0.5, 0) node[below] {$ t_{1} $};
	\draw[dotted] (1.5, 1) -- (1.5, 0) node[below] {$ t_{2} $};
	\draw[dotted] (1.9, 2) -- (1.9, 0) node[below] {$ t_{3} $};
	\draw[dotted] (2.7, 3) -- (2.7, 0) node[below] {$ t_{4} $};
	\draw[dotted] (3.2, 3.2) -- (3.2, 0) node[below] {$ t_{5} $};
	\draw[dotted] (4, 4) -- (4, 0) node[below] {$ t_{6} $};
	
	\draw[black] plot [smooth] coordinates {(0, 0.4) (0.5, 0.5) (1, 0.9) (1.5, 1) (1.9, 2) (2.3, 2.2) (2.7, 3) (3.2, 3.2) (4, 4) (4.5, 4.15)} node[above right] {$ u $};
	
	\draw (0, 0.4) -- (0.5, 0.4);
	\draw (0.5, 0.5) -- (1.5, 0.5);
	\draw (1.5, 1) -- (1.9, 1);
	\draw (1.9, 2) -- (2.7, 2);
	\draw (2.7, 3) -- (3.2, 3);
	\draw (3.2, 3.2) -- (4, 3.2);
	\draw (4, 4) -- (4.5, 4) node[below right] {$ \overline{u} $};

\end{tikzpicture}

\caption{Esempio di grafico di $ u $ (funzione continua) e di $ \overline{u} $ (funzione a tratti)}
\end{figure}
\end{center}

Se $ u \in \mathcal{C}^{1} ([t_{0}, T]) $ allora, con $ t \in [t_{0}, T] $

\[ \vert u(t) - u(t_{n}) \le \left\vert \int\limits_{t_{n}}^{t} u' \right\vert \le \int\limits_{t_{n}}^{t} \vert u' \vert \]

e quindi 

\[ \sup\limits_{t \in [t_{n}, t_{n + 1}]} \vert u(t) - u(t_{n}) \vert \le \int\limits_{t_{n}}^{t_{n + 1}} \vert u' \vert \]


Se $ \tau_{n} = \tau \defeq \frac{T - t_{0}}{N} $, ne segue che

\[ \Vert u - \overline{u} \Vert_{[t_{0}, T]} \le \frac{T - t_{0}}{N} \sup\limits_{t \in [t_{0}, T]} \vert u' \vert \]

ma se $ \tau_{n} $ tale che

\[ \int\limits_{t_{n}}^{t_{n + 1}} \vert u' \vert = \frac{1}{N} \int\limits_{t_{0}}^{T} \vert u' \vert \]

si ha che

\[ \Vert u - \overline{u} \Vert_{[t_{0}, T]} \le \frac{1}{N} \int\limits_{t_{0}}^{T} \vert u' \vert \]

Si osserva che, se $ u_{p} (t) = t^{p} $, con $ p > 0 $ e $ t \in (0, 1) $ si ha

\[ \sup\limits_{t \in (0, 1)} \vert u_{p}' (t) \vert = \begin{cases} \infty & p < 1 \\ p & p \ge 1 \end{cases} \]

e

\[ \int\limits_{0}^{1} \vert u_{p}' \vert = \int\limits_{0}^{1} p t^{p - 1} \, \mathrm{d}t = 1 \]

\section{Passi adattivi - generazione e trasporto dell'errore}
\subsection{Generazione e trasporto dell'errore e scelta dei passi}

\refsec{16} suggerisce di equidistribuire gli "errori locali". Gli "errori locali" vengono interpretati per un metodo a un passo dato da $ \Phi $. Scrivendo

\[ u(t) = \varphi(t, t_{0}) v \]

e

\[
\begin{cases}
U_{0} = v \\
U_{n + 1} = \Phi(t_{n + 1}, t_{n}) U_{n}
\end{cases}
\]

si ha

\[ \varphi(t_{1}, t_{0}) v - \Phi(t_{1}, t_{0}) v = \varepsilon(t_{0}, v; \tau_{0}) \]

dove:
\begin{itemize}
\item $ \varphi(t_{1}, t_{0}) v $ non \`e calcolabile;
\item $ \Phi(t_{1}, t_{0}) v $ \`e calcolabile;
\item $ t_{0} $ e $ v $ sono noti;
\item $ \tau_{0} $ \`e da determinare.
\end{itemize}

per il primo passo, mentre per il passo generico si ha

\begin{dmath*}
u(t_{n + 1}) - U_{n + 1} = \varphi(t_{n + 1}, t_{n}) u(t_{n}) - \Phi (t_{n + 1}, t_{n}) U_{n} = [ \underbrace{\varphi(t_{n + 1}, t_{n}) u(t_{n}) - \Phi (t_{n + 1}, t_{n}) U(t_{n})}_{\varepsilon(t_{n}, u(t_{n}), \tau_{n})}] + [\underbrace{\Phi (t_{n + 1}, t_{n}) U(t_{n}) - \varphi(t_{n + 1}, t_{n}) u(t_{n})}_{\text{trasporto tramite $ \Phi $. "Stabilit\`a discreta"}}]
\end{dmath*}

oppure

\begin{dmath*}
u(t_{n + 1}) - U_{n + 1} = \varphi(t_{n + 1}, t_{n}) u(t_{n}) - \Phi (t_{n + 1}, t_{n}) U_{n} = [ \underbrace{\varphi(t_{n + 1}, t_{n}) u(t_{n}) - \varphi (t_{n + 1}, t_{n}) U_{n}}_{\text{trasporto tramite $ \varphi $. "Stabilit\`a continua"}}] + [\underbrace{\varphi (t_{n + 1}, t_{n}) U_{n} - \Phi(t_{n + 1}, t_{n}) U_{n}}_{\varepsilon(t_{n}, U_{n}, \tau_{n})}]
\end{dmath*}

Ci si limiter\`a a equidistribuire (sostituzioni calcolabili) gli errori di consistenza lungo la soluzione discreta.

\subsection{Un esempio con il residuo}
Si riconsideri l'esempio

\[
\begin{cases}
u(1) = 1 \\
u' = t^{p} u
\end{cases}
\]

in $ (0, 1) $ con il metodo di Eulero esplicito. Si sostituisca l'errore di consistenza con il residuo (locale)

\[ R(t_{n}) = U(t_{n}) - U(t_{n - 1}) - \int\limits_{t_{n - 1}}^{t_{n}} f(t, U(t)) \, \mathrm{d}t = \int\limits_{t_{n - 1}}^{t_{n}} f(t_{n - 1}, U_{n - 1}) - f(t, U(t)) \, \mathrm{d}t \] 

dove $ 1 = t_{0} > t_{1} > \dotsb > t_{N - 1} > t_{N} = 0 $ e $ U $ \`e il poligono di Eulero. La relazione

\[ \mathop{toll} \approx R(t_{n}) = \int\limits_{t_{n}}^{t_{n - 1}} t_{n -1}^{p} U_{n - 1} - t^{p} U(t) \, \mathrm{d}t \approx U_{n - 1} \int\limits_{t_{n}}^{t_{n - 1}} \underbrace{t_{n - 1}^{p} - t^{p}}_{\approx p t_{n - 1}^{p} (t - t_{n})} \, \mathrm{d}t \approx U_{n - 1} p t_{n - 1}^{p - 1} \frac{1}{2} \tau_{n - 1}^{2} \]

suggerisce $ \tau_{n - 1} = \sqrt{\frac{2 \mathop{toll}}{p t_{n - 1}^{p - 1} U_{n - 1}}} $

Si osserva numericamente che:
\begin{enumerate}
\item la scelta per i passi proposta riprende l'EOC (\emph{Experimental order of convergence}, ordine di convergenza sperimentale) 1 nei casi $ p \in (-1, 0) $ al posto di $ 1 + p $;
\item per $ p \gg 1 $ l'errore \`e pi\`u piccolo rispetto a passi uniformi, con l'aumentare di $ p $ questa differenza cresce.
\end{enumerate}

\section{Passi adattivi - stimatori con dilemma}
\subsection{Stimatori per l'errore di consistenza}	\label{section:18.1}

Dati un'evoluzione $ \varphi $ e un metodo ad un passo $ \Phi $ di ordine $ p $ si vuole approssimare numericamente l'errore di consistenza

\[ \varepsilon(t, z, \tau) = \varphi(t, z, \tau) - \Phi(t, z, \tau) \]

Sia $ \Phi' $ un metodo ad un passo di ordine di consistenza $ p' > p $. Fissando $ (t, z) $, si supponga che:
\begin{itemize}
\item $ \frac{\tau^{p + 1}}{\varepsilon(t, z, \tau)} = \mathcal{O}(1) $ per $ \tau \to 0 $
\item $ \varepsilon'(t, z, \tau) = \varphi(t, z, \tau) - \Phi(t, z, \tau) = \mathcal{O}(\tau^{p' + 1}) $
\end{itemize}

Quindi
\[ \forall\ \alpha > 0, \exists\ \tau^{\ast} = \tau^{\ast}(\alpha) : \forall\ \tau \in (0, \tau^{\ast}), \vert \varepsilon'(t, z, \tau) \vert \le \alpha \vert \varepsilon(t, z, \tau) \vert \]

Ci\`o implica che 

\begin{dmath*}
{\vert \Phi'(t + \tau, t)z - \Phi(t + \tau, t)z \vert} \le {\vert \Phi'(t + \tau, t)z - \varphi(t + \tau, t)z \vert} + {\vert \varphi(t + \tau, t)z - \Phi(t + \tau, t)z \vert} = {\vert \varepsilon'(t, z, \tau) \vert} + {\vert \varepsilon(t, z, \tau) \vert} \le {(1 + \alpha) \vert \varepsilon(t, z, \tau) \vert}
\end{dmath*}

Se si sceglie $ \alpha < 1 $ si ha anche 

\begin{dmath*}
{\vert \Phi(t + \tau, t)z - \Phi'(t + \tau, t)z \vert} \ge {\vert \Phi(t + \tau, t)z - \varphi(t + \tau, t)z \vert} - {\vert \underbrace{\Phi'(t + \tau, t)z - \varphi(t + \tau, t)z \vert}_{= \varepsilon'(t, z, \tau)}} \ge {(1 + \alpha) \vert \varepsilon(t, z, \tau) \vert}
\end{dmath*}

Di conseguenza

\begin{equation}	\label{eq:stima181}
\frac{1}{1 + \alpha} \vert [\varepsilon](t, z, \tau) \vert \le \vert \varepsilon(t, z, \tau) \vert \le \frac{1}{1 - \alpha} \vert [\varepsilon(t, z, \tau)](t, z, \tau) \vert
\end{equation}

dove $ [\varepsilon](t, z, \tau) \defeq \Phi'(t, z, \tau) - \Phi(t, z, \tau) $.

\subsection{Un dilemma}
\refsec{18.1} suggerisce che $ [\varepsilon] $ pu\`o essere usato come sostituzione per $ \varepsilon $ per $ \tau $ sufficientemente piccolo. % e...
Comunque in questo caso $ \Phi'(t + \tau, t)z $ \`e disponibile e approssima $ \varphi(t + \tau, t)z $ meglio di $ \Phi(t + \tau, t)z $ ma per $ \varepsilon'(t, z, \tau) $ non si dispone di uno stimatore con $ (\ref{eq:stima181}) $ in \refsec{18.1}. In particolare $ [\varepsilon] $ sovrastimer\`a $ \varepsilon' $ per $ \tau $ piccolo.

Cosa \`e da preferire tra approssimazioni accurati o stimatori accurati? L'esperienza suggerisce la prima.

\subsection{Metodi di Runge-Kutta immersi}
Questo \`e lo schema di Butcher per  i Runge-Kutta immersi

\begin{center}
\begin{tabular}{c|ccc}
                  &   &       & \\
$ \underline{c} $ &   & $ A $ & \\
				  &   &       & \\
\hline
				  &   & $ \underline{b}^{T} $ & \\
\hline
				  &   & $ \hat{\underline{b}}^{T} $ & \\
\end{tabular}
\end{center}

Il metodo dato da $ \underline{b}^{T} $ ha ordine $ p $ mentre quello dato da $ \hat{\underline{b}}^{T} $ ha ordine $ \hat{p} = p - 1 $. Per $ U_{n + 1} = U_{n} + \tau \sum\limits_{i = 1}^{s} b_{i} k_{i} $ e si stima l'errore di consistenza con $ \tau \sum\limits_{i = 1}^{s} (b_{i} - \hat{b}_{i}) k_{i} $.

\end{document}
